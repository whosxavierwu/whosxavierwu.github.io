<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大规模词汇聚类 | whosxavierwu’s blog</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="大规模词汇聚类" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="0、业务背景" />
<meta property="og:description" content="0、业务背景" />
<link rel="canonical" href="http://localhost:4034/clustering/2020/04/29/word-clustering-mapreduce.html" />
<meta property="og:url" content="http://localhost:4034/clustering/2020/04/29/word-clustering-mapreduce.html" />
<meta property="og:site_name" content="whosxavierwu’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-29T22:50:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4034/clustering/2020/04/29/word-clustering-mapreduce.html"},"url":"http://localhost:4034/clustering/2020/04/29/word-clustering-mapreduce.html","headline":"大规模词汇聚类","dateModified":"2020-04-29T22:50:00+08:00","datePublished":"2020-04-29T22:50:00+08:00","description":"0、业务背景","@type":"BlogPosting","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4034/feed.xml" title="whosxavierwu's blog" /></head>
<body><script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">大规模词汇聚类</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-04-29T22:50:00+08:00" itemprop="datePublished">Apr 29, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="0业务背景">0、业务背景</h2>

<p>新人练手项目。给定百家号中汽车类网页语料，需要从中提取出词汇，并对词汇进行聚类。</p>

<h2 id="1问题定义">1、问题定义</h2>

<p>最常见的聚类问题是做句子/文档聚类，而这个任务是词汇聚类，处理起来其实也能用相似的方式。聚类问题的整体处理框架还是：</p>

<ol>
  <li>准备好数据；这里指的是准备好语料，包括数据获取、数据清洗、分词等；</li>
  <li>对要聚类的item，构建对应的特征向量。在这里item指的是一个词；</li>
  <li>选择聚类算法模型进行相应开发；</li>
  <li>基于词向量，进行模型训练；</li>
  <li>取训练后的标签，进行效果评估；</li>
</ol>

<h2 id="2数据准备">2、数据准备</h2>

<h3 id="21-数据源">2.1 数据源</h3>

<p>源数据是百家号中汽车类网页的结构化数据，有125万条；写一个小脚本提取文章内容主体，得到56万篇文章。由于数据schema不明确，提取规则只是基于部分数据来定的，所以可能存在一些网页数据没能正确解析出文章内容主体。56万篇作为语料基本也够用了。</p>

<h3 id="22-数据处理">2.2 数据处理</h3>

<ol>
  <li>对文章进行分句；</li>
  <li>对短句进行分词；</li>
  <li>对词进行清洗、处理；</li>
</ol>

<p>这三步实际上是一起处理的。具体是基于PaddleNLP中分享的<a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/shared_modules/preprocess/tokenizer">tokenizer</a>做了些修改后使用。tokenizer接收的输入是一个句子，输出是进行tokenize后的词汇序列。实际上tokenizer所调用的模型是对单个字符的词性预测，预测的结果中除了词性（名词、动词等）还会带有“是否新词”的信息，进而达到分词的效果。基于此，我做的改动主要是：</p>

<ol>
  <li>为了对文章进行分句，对每个字符判断是否属于“分句符号”，例如逗号、句号、叹号等；如果是，换行输出，将结果由每行一篇文章的格式变成每行一个分句的形式；（之所以要转换格式，因为后续是通过分句来统计词汇共现程度的）</li>
  <li>对于每个字符，在输出前进行了处理：统一大小写、统一标点符号；</li>
  <li>标点符号不输出。避免后续被当做一个“词汇”；</li>
</ol>

<h2 id="3特征工程">3、特征工程</h2>

<p>机器学习领域的基本共识是，数据和特征决定了整体效果的上限，而模型和算法只是不断地逼近这个上限。简单模型加上巧妙的特征工程之后，是可以得到比高深复杂的模型更好的效果的。</p>

<p>用怎样的特征向量来表示一个词汇，我认为可以分浅层和深层来考虑。深层特征要求对词汇的深层次语义有一定程度的理解，更接近自然语言理解的本质；而浅层特征则只停留在词汇的表面特征，例如词频、词共现等统计指标。</p>

<h3 id="31-浅层特征">3.1 浅层特征</h3>

<p>对于词汇的浅层特征，比较简单直接的一种思路是，观察词与词两两之间的共现频率。“共现”可以指两个词出现在同一篇文章、或同一个段落、或同一个句子、或同一个短句；这几种方式的区别在于对词汇上下文考虑的范围不同。</p>

<p>无论哪种方式，我们都需要先统计出词共现矩阵。用$C$表示词共现矩阵，其中元素$c_{ij}$表示词$w_i$与词$w_j$共现的次数。如果预料中共有$N$个词汇，则该矩阵的大小为$N*N$。</p>

<p>通常我们都需要按词频进行一个简单的过滤。在本次语料中，词汇（准确说是token）共有119万个，实际出现过的词对有8100万以上，如果不做删减的基于全量数据处理，后面各部分的效率显然是极低的。在本次任务中，我主要取高频的2~6万词汇。</p>

<p>基于词共现矩阵$C$计算某个词汇$w_i$的特征向量$\vec{v_i}$，可以有这么一些做法：</p>

<ol>
  <li>直接取$C$中对应的一行，即 $\vec{v_i}=(c_{i0}, …, c_{ij}, …)$ ，$v_{ij}=c_{ij}$，向量维度为$N$；</li>
  <li>在第一种方式的基础上，除去该词汇的总出现次数，即 $v_{ij} = \frac{c_{ij}}{\sum_j^N c_{ij}}$ ；</li>
  <li>这第一种方式的基础上，除去与该词汇共现过的词汇的数量，即 $v_{ij} = \frac{c_{ij}}{ count\{j;c_{ij}&gt;0\} }$ ；</li>
  <li>在第一种方式的基础上，进行MinMax归一化，即 $v_{ij} = \frac{c_{ij} - min(c_{ij}) + \epsilon }{ max(c_{ij};j) - min(c_{ij};j) }$ , $s.t. c_{ij}&gt;0$ ；</li>
</ol>

<h3 id="32-深层特征">3.2 深层特征</h3>

<p>深层特征要求对词汇有一定的理解，在深度学习领域一般统称为Embedding。当前较为出名的是Word2Vec、ERNIE、BERT。都是通过大型语料预训练好的词向量。</p>

<h2 id="4模型选择">4、模型选择</h2>

<h3 id="41-kmeans">4.1 KMeans</h3>

<p>KMeans 的核心思想简单明了：</p>

<ol>
  <li>通过某种方式（例如从样本中随机挑选）得到$K$个簇中心的特征向量;</li>
  <li>遍历每个样本点（也就是每个词），计算出离它最近的簇中心，分配到该簇中；</li>
  <li>对于每个簇，根据其中的所有样本点，重新计算（例如直接取均值）簇中心；</li>
  <li>重复2、3两步，直至某个条件；</li>
</ol>

<h3 id="42-minibatchkmeans">4.2 MiniBatchKMeans</h3>

<h2 id="5模型训练">5、模型训练</h2>

<h2 id="6效果评估">6、效果评估</h2>

<h3 id="61-客观指标">6.1 客观指标</h3>

<table>
  <thead>
    <tr>
      <th>指标</th>
      <th>计算方式</th>
      <th>值范围</th>
      <th>值含义</th>
      <th>优点</th>
      <th>缺点</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Inertia</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Silhouette Coefficient</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Calinski-Harabasz Index</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="62-主观评估">6.2 主观评估</h3>

<h2 id="7实验">7、实验</h2>

<h2 id="8思考">8、思考</h2>

<h3 id="81-如何确定k值">8.1 如何确定K值？</h3>

<p>一种方案当然就是人为根据经验或者业务需求来拍一个值了。</p>

<p>另外一种相对可量化的做法是手肘法：取不同的K值各跑一边，观察某个指标的变化，通常来说这个指标在K值较小的时候的，会随着K值的增大而以比较快的速度变化，我们通过绘制相应的图像，来找到那个使效果较为稳定的最小的K值。</p>

<h3 id="82-落地应用场景有哪些">8.2 落地应用场景有哪些？</h3>

<ol>
  <li>用于发现数据规律，找到一些潜在的模式；例如我会发现有一类词是“7500公里”、“8000公里”、“4000公里”；</li>
  <li>用于发现一些近义词，例如我发现有一个簇里面只有两个词：“档”和“挡”；</li>
  <li>可能可以发现同类车；</li>
</ol>

  </div><a class="u-url" href="/clustering/2020/04/29/word-clustering-mapreduce.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">whosxavierwu&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">whosxavierwu&#39;s blog</li><li><a class="u-email" href="mailto:whosxavierwu@gmail.com">whosxavierwu@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/whosxavierwu"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">whosxavierwu</span></a></li><li><a href="https://www.linkedin.com/in/zeweiwu"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">zeweiwu</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Keep learning, deep learning. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
