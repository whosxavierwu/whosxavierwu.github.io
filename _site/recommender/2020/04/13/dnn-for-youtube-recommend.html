<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Deep Neural Network for YouTube Recommendation System | whosxavierwu’s blog</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Deep Neural Network for YouTube Recommendation System" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="概述" />
<meta property="og:description" content="概述" />
<link rel="canonical" href="http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html" />
<meta property="og:url" content="http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html" />
<meta property="og:site_name" content="whosxavierwu’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-13T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html"},"url":"http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html","headline":"Deep Neural Network for YouTube Recommendation System","dateModified":"2020-04-13T00:00:00+08:00","datePublished":"2020-04-13T00:00:00+08:00","description":"概述","@type":"BlogPosting","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4034/feed.xml" title="whosxavierwu's blog" /></head>
<body><script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Deep Neural Network for YouTube Recommendation System</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-04-13T00:00:00+08:00" itemprop="datePublished">Apr 13, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="概述">概述</h1>

<p>这篇论文是对YouTube中基于DNN的推荐系统的整体描述。本文旨在对论文进行总结。</p>

<p>整个系统主要分 Candidate Generation 和 Ranking，也就是召回和排序两部分。召回模块从数百万的视频集合中挑选出数百个候选视频；排序模块则是从数百个中挑选出几十个视频，并排序后推送给用户。</p>

<p>下图是整体框架：</p>

<p><img src="/assets/youtube-dnn-whole.jpg" alt="整体框架" /></p>

<h1 id="一召回">一、召回</h1>

<p><img src="/assets/youtube-dnn-candidate-generate.jpg" alt="Candidate Generation" /></p>

<h2 id="1-问题定义">1. 问题定义</h2>

<p>YouTube将召回问题转化为一个多分类问题去处理，建模以预测：在$t$时刻发生的某次视频观看事件$w_t$中，具体观看的是视频集合$V$中的哪个视频。</p>

<p>假设用$U$表示这次事件中的用户，用$C$表示上下文，用$u$表示对$U$、$C$一起进行embedding后的特征向量，用$v_i$表示对视频$i$进行embedding后的特征向量。则我们需要预测的分类到视频$i$的概率可以形式化如下：</p>

<script type="math/tex; mode=display">P(w_t=i|U,C)=\frac{e^{v_iu}}{\sum_{j\in V}e^{v_ju}}</script>

<p>通过这样的问题转化以后，理想情况下，我们能预测到在当前用户、当前情景下，每个视频被观看的概率。取概率最高的前M个视频即可作为召回模块的输出。</p>

<h2 id="2-数据准备">2. 数据准备</h2>

<p>在准备数据样本时，需要注意：</p>

<ol>
  <li>数据源方面，采用所有YouTube视频的观看事件（如嵌在其他网站的视频等），而不仅仅是YouTube主站上的。</li>
  <li>对每个用户带来的训练样本数进行了限制，从而避免高活跃用户对模型的过度影响。</li>
  <li>注意避免样本数据中掺入未来信息，模型的输入应该始终只有打标签以前的数据。</li>
</ol>

<p><img src="/assets/youtube-dnn-dataset.jpg" alt="训练数据筛选" /></p>

<h2 id="3-特征处理">3. 特征处理</h2>

<p>特征方面，抽象来看，主要涉及用户属性、用户行为与事件时间特征三大块。作者在论文中给出了不同特征组合的效果对比：</p>

<p><img src="/assets/youtube-dnn-feature-select.jpg" alt="Features" /></p>

<h3 id="31-用户属性特征">3.1 用户属性特征</h3>

<p>用户属性特征在论文中只是简单的一笔带过，包括：用户处理的地理位置、设备、性别、登录状态、年龄。直觉来看，这类特征应该对新用户的推荐效果有着重要影响。</p>

<p>尽管没有细讲，从最后对不同特征组合的实验来看，却似乎带有很大的提升：”All Features”相对于”Watches, Searches &amp; Example Age”有显著提升。</p>

<h3 id="32-用户行为特征">3.2 用户行为特征</h3>

<p>对用户行为的特征挖掘，主要从用户的视频观看历史（”watch vector”）与搜索历史（”search vector”）着手。</p>

<h4 id="watch-vector">“watch vector”</h4>

<p>从用户的视频观看历史中挖掘特征主要分两步：</p>
<ol>
  <li>通过单独的模型预训练好每个视频的embedding。</li>
  <li>取出用户历史（<em>All or Top-k?</em>）观看的视频的embedding取均值，作为 “watch vectors”。</li>
</ol>

<p>具体而言，是如何做embedding的呢？文中只是简单的提了一下：</p>

<blockquote>
  <p>Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a fixed vocabulary</p>
</blockquote>

<p>从我的理解来看，应该是将每个用户历史观看的视频ID序列，看作一个“句子”，所有用户的“句子”汇聚成一个语料集合；进而参考Word2Vec中基于CBOW的训练方式来做训练，从而获得每个视频的embedding。</p>

<p>作者还提到了一句：</p>

<blockquote>
  <p>Importantly, the embeddings are learned jointly with all other model parameters through normal gradient descent backpropagation updates</p>
</blockquote>

<p>这个我不太理解。</p>

<h4 id="search-vector">“search vector”</h4>

<p>从用户的搜索历史中挖掘特征的步骤，与前面相似：</p>
<ol>
  <li>将每个query分词成unigrams跟bigrams，而token又是被embedding好的，</li>
  <li>汇总所有的这些embedding求均值，作为 “search vector”</li>
</ol>

<blockquote>
  <p>Search history is treated similarly to watch history - each query is tokenized into unigrams and bigrams and each token is embedded. Once averaged, the user’s tokenized, embedded queries represent a summarized dense search history</p>
</blockquote>

<p>从作者的描述来看，应该就是基于用户的搜索预料来训练Word2Vec模型，从而得到embedding向量。</p>

<h3 id="33-事件时间特征">3.3 事件时间特征</h3>

<p>“Example Age” 是个较为特殊的特征。引入这个特征，是因为作者观察到，用户更偏好新产的视频。</p>

<blockquote>
  <p>we feed the age of the training example as a feature during training. At serving time, this feature is set to zero (or slightly negative) to reflect that the model is making predictions at the very end of the training window.</p>
</blockquote>

<p>论文在一张插图的描述中提到：</p>

<blockquote>
  <p>the example age is expressed as $t_{max} - t_N$ where $t_{max}$ is the maximum observed time in the training data.</p>
</blockquote>

<p>$t_N$指的是样本打标签的时间，也就是当前的事件的时间戳，这个好理解。</p>

<p>虽然说得比较模糊，但结合前面的描述：在serving时，该特征被置为零。所以$t_{max}$应该是指全体训练样本中的最大观测时间。</p>

<p>至于具体是用秒？分钟？小时？还是天？则没有提及，考虑到不同量纲之间可以通过线性变换来相互切换，所以这个问题的影响不大。</p>

<p>作者通过统计分析表明，模型在加入了”Example Age”之后，能比较好的捕捉到视频上传时间的影响。</p>

<p><img src="/assets/youtube-dnn-example-age.jpg" alt="Example Age" /></p>

<p>那么问题来了，为什么不直接用”Days Since Upload”来做特征呢？</p>

<h2 id="4-模型训练与线上服务">4. 模型训练与线上服务</h2>

<h3 id="41-训练技巧-negative-sampling">4.1 训练技巧： Negative Sampling</h3>

<p>一般情况下，基于 SoftMax 的 Cross-Entropy Loss 形式如下：</p>

<script type="math/tex; mode=display">logit(i)=\frac{exp(w_{i}x)}{\sum^{M}_{j}{exp({w_{j}x})}}</script>

<script type="math/tex; mode=display">loss=-log(logit(i))=-(w_ix)+log(\sum^{M}_{j}{exp(w_jx)})</script>

<p>可以看到，当类别数$M$多达数百万的时候，损失函数的后半部分$ log(\sum^{M}_{j}exp(w_jx)) $的计算量将会特别大。</p>

<p>而 Negative Sampling 的思路则是，通过采样指定$K$个类别，从而把计算量从$O(M) \to O(K)$控制了下来。作者在论文中指出，一般$K$取数千。</p>

<p>这里有几个细节：</p>

<ol>
  <li>$K$是否把类别$i$包含在内？</li>
  <li>具体如何进行随机采样？均匀采样？</li>
  <li>是每个训练样本都做一次采样？还是每个batch做一次采样？</li>
  <li>每次负采样、训练时，并不会更新$K$个被选中的类别以外的类别权重。那么如果存在某个类别的样本数量相对较大，会不会对模型效果有影响？</li>
</ol>

<h3 id="42-线上服务">4.2 线上服务</h3>

<p><img src="/assets/youtube-dnn-recall-serving.jpg" alt="Candidate Generation Serving" /></p>

<p>模型框架图中的这个细节，是我一开始没有留意到的。</p>

<p>当时只是想当然的认为，在做serving时，每次用户来到时，跑一遍模型预测，然后取出概率值Top N的视频来召回。而从YouTube的框架图来看，实际做serving时是以下步骤：</p>

<ol>
  <li>从最后一层ReLU层获取用户向量$\vec{u}$（256维）；</li>
  <li>从SoftMax层获取视频向量$\vec{v_j}$；</li>
  <li>通过最近邻搜索来找到近似的Top N视频。</li>
</ol>

<p>以上的简要描述可能仍然不好理解。</p>

<p>我们知道，在ReLU和SoftMax两层之间存在一个大小为$(256, V)$的权重矩阵$\vec{W}$，$V$表示视频总数；$\vec{W}$通过训练学习到。</p>

<p>来看常规的feedward流程：</p>

<ol>
  <li>计算至最后的ReLU层得到$\vec{u}$；</li>
  <li>进行矩阵乘法$\vec{z}=\vec{u}^T\vec{W}$；</li>
  <li>进行指数运算$exp(\vec{z})$；</li>
  <li>归一化$\vec{y}=exp(\vec{z})/||exp(\vec{z})||_1$；</li>
  <li>按$y_j$进行倒序取Top-N视频作为召回结果；</li>
</ol>

<p>观察到，由于指数运算具有单调性，且在进行召回时只关注模型输出的相对值，而不关注绝对值；我们发现3、4两步可以省略掉，直接在计算出${\vec{z}}$之后，取$z_j$的值来作为排序的依据即可。</p>

<p>由于视频数量巨大，$\vec{z}=\vec{u}^T\vec{W}$这一步仍然存在高昂的计算成本。为了提升效率，在完成了模型训练之后，可以提前把$\vec{W}$拆成一个个列向量$\vec{v_j}$。</p>

<p>线上serving时，计算出用户向量$\vec{u}$之后，下一步就变成了寻找与$\vec{u}$内积最大的N个列向量${\vec{v_j}}$的问题。而这可以转化为最近邻搜索问题（作者引用论文：<a href="http://www.cs.cmu.edu/~agray/approxnn.pdf">An investigation of practical approximate nearest neighbor</a>）。</p>

<h1 id="二排序">二、排序</h1>

<p><img src="/assets/youtube-dnn-ranking.jpg" alt="Ranking" /></p>

<h2 id="1-问题定义-1">1. 问题定义</h2>

<p>YouTube的推荐系统中，将排序问题转化为预测：给用户$u_i$曝光视频$v_j$后，用户的观看时长。</p>

<p>为什么不转化为预测CTR？因为光看CTR容易使模型偏好“标题党”或者“封面党”，进而影响用户体验、商业变现等。</p>

<h2 id="2-数据准备-1">2. 数据准备</h2>

<p>对于每一次视频曝光事件（给用户$u_i$曝光视频$v_j$），如果用户点击观看了视频，则取视频观看时长$T_i$作为预测值；如果没有点击，则取单位值作为预测值。</p>

<h2 id="3-特征处理-1">3. 特征处理</h2>

<p><img src="/assets/youtube-dnn-ranking-feature.jpg" alt="Ranking Features" /></p>

<p>论文中简单的按照特征值类型分别展开论述。</p>

<h3 id="31-离散值特征">3.1 离散值特征</h3>

<p>离散值特征需要进行embedding，在图中也展示了主要的两种：对视频ID的embedding，以及对文本的embedding。</p>

<h4 id="video-embedding">“video embedding”</h4>

<p>对于视频ID，先按照召回模块中相似的处理方式（是否完全一样？），单独训练得到video embedding，维度约为$klog(V)$。<strong>注意：作者提到，对于点击次数较少的长尾视频，直接采用零向量作为embedding。</strong></p>

<ul>
  <li>对于模型输入的视频ID（有且仅有一个），直接取相应的embedding输入到网络中；</li>
  <li>对于用户观看过的视频ID序列（全部或者最近K个？），获取相应的embedding取均值输入到网络中；</li>
</ul>

<h4 id="language-embedding">“language embedding”</h4>

<p>图中说得很模糊，按我理解应该是指文本相关的特征，包括对”user language”、”video language”两块的embedding。这两方面具体是指哪些信息？不知道。</p>

<h3 id="32-连续值特征">3.2. 连续值特征</h3>

<p>对于连续值特征，YouTube采用了颇为特别的处理方式。</p>

<p>首先是对连续值特征进行正则化：假设$x$的分布函数是$f$，则通过$\tilde{x}=\int^{x}_{-\infty}{df}$进行正则化。式中的积分，通过基于特征值分位数的线性插值进行估计。更具体的操作论文中没有展开说。</p>

<blockquote>
  <p>A continuous feature x with distribution f is transformed to $\tilde{x}$ by scaling the values such that the feature is equally distributed in [0, 1) using the cumulative distribution, $\tilde{x}=\int^{x}_{-\infty}{df}$. This integral is approximated with linear interpolation on the quantiles of the feature values computed in a single pass over the data before training begins.</p>
</blockquote>

<p>其次是在正则化后的值基础上，还通过取平方${\tilde{x}}^2$与开根号$\sqrt{\tilde{x}}$引入了两种特征值，进而引入了非线性特征。</p>

<p>架构图中明确指出进行了正则化的特征有两个：</p>

<ol>
  <li>“time since last watch”，也就是“距离上一次观看的时间”。但具体来讲，“上一次观看”是指“该视频上一次被任意用户观看的时间”？还是“该用户上一次观看任意视频的时间”？还是“该用户对该视频的上一次观看的时间”？不得而知。</li>
  <li>”# previous impressions”，也就是“此前曝光的数量”。但具体来讲，“曝光”是指“给该用户的该视频的曝光次数”？还是“给该用户的任意视频的曝光次数”？还是“给任意用户的该视频的曝光次数”？这里我认为是第一种，因为论文在其他地方提到，如果已经给用户曝光过某视频但用户没有点击，那后面应该逐渐减少这个视频的推荐，进而从用户的角度看，推荐列表是在逐渐变化的。</li>
</ol>

<h3 id="33-其他">3.3 其他</h3>

<p>其他一些论文中提到了，但是没有放到图中的，大概有这些：</p>

<ul>
  <li>用户看过多少同频道的视频？</li>
  <li>用户上一次看同频道或同主题的视频是什么时候？</li>
  <li>用户过往与相似视频的交互特征特别重要</li>
  <li>来自召回模块的特征</li>
  <li>用户是否登录</li>
</ul>

<h2 id="4-模型训练与线上服务-1">4. 模型训练与线上服务</h2>

<p>直觉来看，既然将排序问题转化为预测问题，似乎应该和常见的回归模型一样，用均方差等作为损失函数才对，而YouTube并没有这样做，而是用 Cross-Entropy 结合 Logistic Regression，为什么可以这么做呢？</p>

<p>我们知道，Sigmoid函数可以通过对对数几率进行线性回归推导得到：</p>

<script type="math/tex; mode=display">odds=\frac{\hat{y}}{1-\hat{y}} \\
log(odds)=log(\frac{\hat{y}}{1-\hat{y}})=\vec{w}^T\vec{x}+b</script>

<script type="math/tex; mode=display">\hat{y} = \frac{1}{1+exp(-(\vec{w}^T\vec{x}+b))}</script>

<p>上面的推导中，出发点是对$odds$的定义，我们将其定义为正样本概率与负样本概率的比例，值越大说明正负样本概率之间差距越大。对第二个式子做简单变换，得到： $odds=exp(\vec{w}^T\vec{x}+b)$。</p>

<p>前面的$odds$我们可以认为是对点击事件的几率进行计算，也就是$odds(Click)$。下面来考虑基于视频观看时长计算几率。我们假设样本总数为$N$，其中正样本（点击并观看视频）的数量为$K$，正样本中视频观看时长记为$T_i$，负样本的视频观看时长统一认为是1，则$odds(WatchTime)$如下：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
odds &=\frac{E[T|Clicked]}{E[T|NotClicked]} =\frac{\frac{\sum^{K}_{i}{T_i}}{N-K+\sum^{K}_{i}{T_i}}}{\frac{N-K}{N-K+\sum^{K}_{i}{T_i}}} \\
&=\frac{\sum^{K}_{i}{T_i}}{N-K} \\
&=\frac{\sum^{K}_{i}{T_i}}{N}*\frac{N}{N-K} \\
&=\frac{\sum^{K}_{i}{T_i}}{N}*\frac{1}{1-K/N} \\
&=\frac{E[T]}{1-ctr}
\end{align} %]]></script>

<p>于是，当$ctr$较小时，$odds$是接近于$E[T]$的；而YouTube框架图中的这看似诡异的部分，背后思想则源于此：</p>

<p><img src="/assets/youtube-dnn-ranking-serving.jpg" alt="Ranking Serving" /></p>

<p>serving时采用几率$odds$，而不是$sigmoid$来作为对视频观看时长的近似。</p>

<p>而训练时，采用 Weighted Logistic Regression：对正样本按$T_i$加权，对负样本按$1$加权。</p>

<h1 id="结语">结语</h1>

<p>把这篇论文读下来，零零散散花了我三四天；整理成脑图的过程中，陆续发现了很多细节问题，又花了一天；写博客的过程中，抠细节、查资料、补知识点，花了三天时间。这一番折腾下来实在太累，好在YouTube的这篇论文也完全值得我这番精读。</p>

<p>目前文中还是不得已的留下了很多未找到答案的疑问，留着后续慢慢填坑了。</p>

<h1 id="参考">参考</h1>

<ol>
  <li><a href="https://dl.acm.org/doi/10.1145/2959100.2959190">论文地址</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/52169807">王喆-整体介绍</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/52504407">王喆-十个工程问题</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/61827629">王喆-模型Serving</a></li>
  <li><a href="https://zhuanlan.zhihu.com/p/38638747">工程再现</a></li>
</ol>

  </div><a class="u-url" href="/recommender/2020/04/13/dnn-for-youtube-recommend.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">whosxavierwu&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">whosxavierwu&#39;s blog</li><li><a class="u-email" href="mailto:whosxavierwu@gmail.com">whosxavierwu@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/whosxavierwu"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">whosxavierwu</span></a></li><li><a href="https://www.linkedin.com/in/zeweiwu"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">zeweiwu</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Keep learning, deep learning. </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
