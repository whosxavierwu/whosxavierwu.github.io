<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.2">Jekyll</generator><link href="http://localhost:4034/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4034/" rel="alternate" type="text/html" /><updated>2020-04-18T17:55:11+08:00</updated><id>http://localhost:4034/</id><title type="html">whosxavierwu’s blog</title><subtitle>Keep learning, deep learning. </subtitle><entry><title type="html">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</title><link href="http://localhost:4034/recommender/2020/04/18/are-we-making-much-progress.html" rel="alternate" type="text/html" title="Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches" /><published>2020-04-18T00:00:00+08:00</published><updated>2020-04-18T00:00:00+08:00</updated><id>http://localhost:4034/recommender/2020/04/18/are-we-making-much-progress</id><content type="html" xml:base="http://localhost:4034/recommender/2020/04/18/are-we-making-much-progress.html">&lt;h1 id=&quot;概述&quot;&gt;概述&lt;/h1&gt;

&lt;p&gt;这篇 RecSys 2019 的 Best Paper，从标题看来就很强，有种“在座各位都是……”的感觉。这两天通读下来，个人认为论文的贡献主要还是在于对学界敲响警钟，而不在于 new idea。&lt;/p&gt;

&lt;p&gt;总的来说，作者从2018年的顶会里挑选了18篇文章（基于深度学习的推荐模型），发现其中只有7篇的结果能被不那么难的进行复现，而这7篇之中有6篇是往往能被相对简单的算法超越。剩下的一篇确实能显著的超越baseline，但并不总能超越非神经网络的线性排序算法。&lt;/p&gt;

&lt;p&gt;毕竟通篇强调 Reproducibility，作者当然有将实验代码公开到 GitHub 上： &lt;a href=&quot;https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation&quot;&gt;https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation&lt;/a&gt;，有兴趣的同学可以进一步研究。&lt;/p&gt;

&lt;h1 id=&quot;论文列表&quot;&gt;论文列表&lt;/h1&gt;

&lt;h1 id=&quot;baseline&quot;&gt;Baseline&lt;/h1&gt;

&lt;h1 id=&quot;实验&quot;&gt;实验&lt;/h1&gt;

&lt;h1 id=&quot;结语&quot;&gt;结语&lt;/h1&gt;

&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;</content><author><name></name></author><summary type="html">概述</summary></entry><entry><title type="html">Deep Neural Network for YouTube Recommendation System</title><link href="http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html" rel="alternate" type="text/html" title="Deep Neural Network for YouTube Recommendation System" /><published>2020-04-13T00:00:00+08:00</published><updated>2020-04-13T00:00:00+08:00</updated><id>http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend</id><content type="html" xml:base="http://localhost:4034/recommender/2020/04/13/dnn-for-youtube-recommend.html">&lt;h1 id=&quot;概述&quot;&gt;概述&lt;/h1&gt;

&lt;p&gt;这篇论文是对YouTube中基于DNN的推荐系统的整体描述。本文旨在对论文进行总结。&lt;/p&gt;

&lt;p&gt;整个系统主要分 Candidate Generation 和 Ranking，也就是召回和排序两部分。召回模块从数百万的视频集合中挑选出数百个候选视频；排序模块则是从数百个中挑选出几十个视频，并排序后推送给用户。&lt;/p&gt;

&lt;p&gt;下图是整体框架：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-whole.jpg&quot; alt=&quot;整体框架&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;一召回&quot;&gt;一、召回&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-candidate-generate.jpg&quot; alt=&quot;Candidate Generation&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-问题定义&quot;&gt;1. 问题定义&lt;/h2&gt;

&lt;p&gt;YouTube将召回问题转化为一个多分类问题去处理，建模以预测：在$t$时刻发生的某次视频观看事件$w_t$中，具体观看的是视频集合$V$中的哪个视频。&lt;/p&gt;

&lt;p&gt;假设用$U$表示这次事件中的用户，用$C$表示上下文，用$u$表示对$U$、$C$一起进行embedding后的特征向量，用$v_i$表示对视频$i$进行embedding后的特征向量。则我们需要预测的分类到视频$i$的概率可以形式化如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(w_t=i|U,C)=\frac{e^{v_iu}}{\sum_{j\in V}e^{v_ju}}&lt;/script&gt;

&lt;p&gt;通过这样的问题转化以后，理想情况下，我们能预测到在当前用户、当前情景下，每个视频被观看的概率。取概率最高的前M个视频即可作为召回模块的输出。&lt;/p&gt;

&lt;h2 id=&quot;2-数据准备&quot;&gt;2. 数据准备&lt;/h2&gt;

&lt;p&gt;在准备数据样本时，需要注意：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;数据源方面，采用所有YouTube视频的观看事件（如嵌在其他网站的视频等），而不仅仅是YouTube主站上的。&lt;/li&gt;
  &lt;li&gt;对每个用户带来的训练样本数进行了限制，从而避免高活跃用户对模型的过度影响。&lt;/li&gt;
  &lt;li&gt;注意避免样本数据中掺入未来信息，模型的输入应该始终只有打标签以前的数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-dataset.jpg&quot; alt=&quot;训练数据筛选&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-特征处理&quot;&gt;3. 特征处理&lt;/h2&gt;

&lt;p&gt;特征方面，抽象来看，主要涉及用户属性、用户行为与事件时间特征三大块。作者在论文中给出了不同特征组合的效果对比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-feature-select.jpg&quot; alt=&quot;Features&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;31-用户属性特征&quot;&gt;3.1 用户属性特征&lt;/h3&gt;

&lt;p&gt;用户属性特征在论文中只是简单的一笔带过，包括：用户处理的地理位置、设备、性别、登录状态、年龄。直觉来看，这类特征应该对新用户的推荐效果有着重要影响。&lt;/p&gt;

&lt;p&gt;尽管没有细讲，从最后对不同特征组合的实验来看，却似乎带有很大的提升：”All Features”相对于”Watches, Searches &amp;amp; Example Age”有显著提升。&lt;/p&gt;

&lt;h3 id=&quot;32-用户行为特征&quot;&gt;3.2 用户行为特征&lt;/h3&gt;

&lt;p&gt;对用户行为的特征挖掘，主要从用户的视频观看历史（”watch vector”）与搜索历史（”search vector”）着手。&lt;/p&gt;

&lt;h4 id=&quot;watch-vector&quot;&gt;“watch vector”&lt;/h4&gt;

&lt;p&gt;从用户的视频观看历史中挖掘特征主要分两步：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;通过单独的模型预训练好每个视频的embedding。&lt;/li&gt;
  &lt;li&gt;取出用户历史（&lt;em&gt;All or Top-k?&lt;/em&gt;）观看的视频的embedding取均值，作为 “watch vectors”。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体而言，是如何做embedding的呢？文中只是简单的提了一下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a fixed vocabulary&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从我的理解来看，应该是将每个用户历史观看的视频ID序列，看作一个“句子”，所有用户的“句子”汇聚成一个语料集合；进而参考Word2Vec中基于CBOW的训练方式来做训练，从而获得每个视频的embedding。&lt;/p&gt;

&lt;p&gt;作者还提到了一句：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Importantly, the embeddings are learned jointly with all other model parameters through normal gradient descent backpropagation updates&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这个我不太理解。&lt;/p&gt;

&lt;h4 id=&quot;search-vector&quot;&gt;“search vector”&lt;/h4&gt;

&lt;p&gt;从用户的搜索历史中挖掘特征的步骤，与前面相似：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;将每个query分词成unigrams跟bigrams，而token又是被embedding好的，&lt;/li&gt;
  &lt;li&gt;汇总所有的这些embedding求均值，作为 “search vector”&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Search history is treated similarly to watch history - each query is tokenized into unigrams and bigrams and each token is embedded. Once averaged, the user’s tokenized, embedded queries represent a summarized dense search history&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从作者的描述来看，应该就是基于用户的搜索预料来训练Word2Vec模型，从而得到embedding向量。&lt;/p&gt;

&lt;h3 id=&quot;33-事件时间特征&quot;&gt;3.3 事件时间特征&lt;/h3&gt;

&lt;p&gt;“Example Age” 是个较为特殊的特征。引入这个特征，是因为作者观察到，用户更偏好新产的视频。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;we feed the age of the training example as a feature during training. At serving time, this feature is set to zero (or slightly negative) to reflect that the model is making predictions at the very end of the training window.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;论文在一张插图的描述中提到：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;the example age is expressed as $t_{max} - t_N$ where $t_{max}$ is the maximum observed time in the training data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;$t_N$指的是样本打标签的时间，也就是当前的事件的时间戳，这个好理解。&lt;/p&gt;

&lt;p&gt;虽然说得比较模糊，但结合前面的描述：在serving时，该特征被置为零。所以$t_{max}$应该是指全体训练样本中的最大观测时间。&lt;/p&gt;

&lt;p&gt;至于具体是用秒？分钟？小时？还是天？则没有提及，考虑到不同量纲之间可以通过线性变换来相互切换，所以这个问题的影响不大。&lt;/p&gt;

&lt;p&gt;作者通过统计分析表明，模型在加入了”Example Age”之后，能比较好的捕捉到视频上传时间的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-example-age.jpg&quot; alt=&quot;Example Age&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么问题来了，为什么不直接用”Days Since Upload”来做特征呢？&lt;/p&gt;

&lt;h2 id=&quot;4-模型训练与线上服务&quot;&gt;4. 模型训练与线上服务&lt;/h2&gt;

&lt;h3 id=&quot;41-训练技巧-negative-sampling&quot;&gt;4.1 训练技巧： Negative Sampling&lt;/h3&gt;

&lt;p&gt;一般情况下，基于 SoftMax 的 Cross-Entropy Loss 形式如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;logit(i)=\frac{exp(w_{i}x)}{\sum^{M}_{j}{exp({w_{j}x})}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;loss=-log(logit(i))=-(w_ix)+log(\sum^{M}_{j}{exp(w_jx)})&lt;/script&gt;

&lt;p&gt;可以看到，当类别数$M$多达数百万的时候，损失函数的后半部分$ log(\sum^{M}_{j}exp(w_jx)) $的计算量将会特别大。&lt;/p&gt;

&lt;p&gt;而 Negative Sampling 的思路则是，通过采样指定$K$个类别，从而把计算量从$O(M) \to O(K)$控制了下来。作者在论文中指出，一般$K$取数千。&lt;/p&gt;

&lt;p&gt;这里有几个细节：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$K$是否把类别$i$包含在内？&lt;/li&gt;
  &lt;li&gt;具体如何进行随机采样？均匀采样？&lt;/li&gt;
  &lt;li&gt;是每个训练样本都做一次采样？还是每个batch做一次采样？&lt;/li&gt;
  &lt;li&gt;每次负采样、训练时，并不会更新$K$个被选中的类别以外的类别权重。那么如果存在某个类别的样本数量相对较大，会不会对模型效果有影响？&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;42-线上服务&quot;&gt;4.2 线上服务&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-recall-serving.jpg&quot; alt=&quot;Candidate Generation Serving&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型框架图中的这个细节，是我一开始没有留意到的。&lt;/p&gt;

&lt;p&gt;当时只是想当然的认为，在做serving时，每次用户来到时，跑一遍模型预测，然后取出概率值Top N的视频来召回。而从YouTube的框架图来看，实际做serving时是以下步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从最后一层ReLU层获取用户向量$\vec{u}$（256维）；&lt;/li&gt;
  &lt;li&gt;从SoftMax层获取视频向量$\vec{v_j}$；&lt;/li&gt;
  &lt;li&gt;通过最近邻搜索来找到近似的Top N视频。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上的简要描述可能仍然不好理解。&lt;/p&gt;

&lt;p&gt;我们知道，在ReLU和SoftMax两层之间存在一个大小为$(256, V)$的权重矩阵$\vec{W}$，$V$表示视频总数；$\vec{W}$通过训练学习到。&lt;/p&gt;

&lt;p&gt;来看常规的feedward流程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算至最后的ReLU层得到$\vec{u}$；&lt;/li&gt;
  &lt;li&gt;进行矩阵乘法$\vec{z}=\vec{u}^T\vec{W}$；&lt;/li&gt;
  &lt;li&gt;进行指数运算$exp(\vec{z})$；&lt;/li&gt;
  &lt;li&gt;归一化$\vec{y}=exp(\vec{z})/||exp(\vec{z})||_1$；&lt;/li&gt;
  &lt;li&gt;按$y_j$进行倒序取Top-N视频作为召回结果；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;观察到，由于指数运算具有单调性，且在进行召回时只关注模型输出的相对值，而不关注绝对值；我们发现3、4两步可以省略掉，直接在计算出${\vec{z}}$之后，取$z_j$的值来作为排序的依据即可。&lt;/p&gt;

&lt;p&gt;由于视频数量巨大，$\vec{z}=\vec{u}^T\vec{W}$这一步仍然存在高昂的计算成本。为了提升效率，在完成了模型训练之后，可以提前把$\vec{W}$拆成一个个列向量$\vec{v_j}$。&lt;/p&gt;

&lt;p&gt;线上serving时，计算出用户向量$\vec{u}$之后，下一步就变成了寻找与$\vec{u}$内积最大的N个列向量${\vec{v_j}}$的问题。而这可以转化为最近邻搜索问题（作者引用论文：&lt;a href=&quot;http://www.cs.cmu.edu/~agray/approxnn.pdf&quot;&gt;An investigation of practical approximate nearest neighbor&lt;/a&gt;）。&lt;/p&gt;

&lt;h1 id=&quot;二排序&quot;&gt;二、排序&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-ranking.jpg&quot; alt=&quot;Ranking&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-问题定义-1&quot;&gt;1. 问题定义&lt;/h2&gt;

&lt;p&gt;YouTube的推荐系统中，将排序问题转化为预测：给用户$u_i$曝光视频$v_j$后，用户的观看时长。&lt;/p&gt;

&lt;p&gt;为什么不转化为预测CTR？因为光看CTR容易使模型偏好“标题党”或者“封面党”，进而影响用户体验、商业变现等。&lt;/p&gt;

&lt;h2 id=&quot;2-数据准备-1&quot;&gt;2. 数据准备&lt;/h2&gt;

&lt;p&gt;对于每一次视频曝光事件（给用户$u_i$曝光视频$v_j$），如果用户点击观看了视频，则取视频观看时长$T_i$作为预测值；如果没有点击，则取单位值作为预测值。&lt;/p&gt;

&lt;h2 id=&quot;3-特征处理-1&quot;&gt;3. 特征处理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-ranking-feature.jpg&quot; alt=&quot;Ranking Features&quot; /&gt;&lt;/p&gt;

&lt;p&gt;论文中简单的按照特征值类型分别展开论述。&lt;/p&gt;

&lt;h3 id=&quot;31-离散值特征&quot;&gt;3.1 离散值特征&lt;/h3&gt;

&lt;p&gt;离散值特征需要进行embedding，在图中也展示了主要的两种：对视频ID的embedding，以及对文本的embedding。&lt;/p&gt;

&lt;h4 id=&quot;video-embedding&quot;&gt;“video embedding”&lt;/h4&gt;

&lt;p&gt;对于视频ID，先按照召回模块中相似的处理方式（是否完全一样？），单独训练得到video embedding，维度约为$klog(V)$。&lt;strong&gt;注意：作者提到，对于点击次数较少的长尾视频，直接采用零向量作为embedding。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于模型输入的视频ID（有且仅有一个），直接取相应的embedding输入到网络中；&lt;/li&gt;
  &lt;li&gt;对于用户观看过的视频ID序列（全部或者最近K个？），获取相应的embedding取均值输入到网络中；&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;language-embedding&quot;&gt;“language embedding”&lt;/h4&gt;

&lt;p&gt;图中说得很模糊，按我理解应该是指文本相关的特征，包括对”user language”、”video language”两块的embedding。这两方面具体是指哪些信息？不知道。&lt;/p&gt;

&lt;h3 id=&quot;32-连续值特征&quot;&gt;3.2. 连续值特征&lt;/h3&gt;

&lt;p&gt;对于连续值特征，YouTube采用了颇为特别的处理方式。&lt;/p&gt;

&lt;p&gt;首先是对连续值特征进行正则化：假设$x$的分布函数是$f$，则通过$\tilde{x}=\int^{x}_{-\infty}{df}$进行正则化。式中的积分，通过基于特征值分位数的线性插值进行估计。更具体的操作论文中没有展开说。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A continuous feature x with distribution f is transformed to $\tilde{x}$ by scaling the values such that the feature is equally distributed in [0, 1) using the cumulative distribution, $\tilde{x}=\int^{x}_{-\infty}{df}$. This integral is approximated with linear interpolation on the quantiles of the feature values computed in a single pass over the data before training begins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其次是在正则化后的值基础上，还通过取平方${\tilde{x}}^2$与开根号$\sqrt{\tilde{x}}$引入了两种特征值，进而引入了非线性特征。&lt;/p&gt;

&lt;p&gt;架构图中明确指出进行了正则化的特征有两个：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“time since last watch”，也就是“距离上一次观看的时间”。但具体来讲，“上一次观看”是指“该视频上一次被任意用户观看的时间”？还是“该用户上一次观看任意视频的时间”？还是“该用户对该视频的上一次观看的时间”？不得而知。&lt;/li&gt;
  &lt;li&gt;”# previous impressions”，也就是“此前曝光的数量”。但具体来讲，“曝光”是指“给该用户的该视频的曝光次数”？还是“给该用户的任意视频的曝光次数”？还是“给任意用户的该视频的曝光次数”？这里我认为是第一种，因为论文在其他地方提到，如果已经给用户曝光过某视频但用户没有点击，那后面应该逐渐减少这个视频的推荐，进而从用户的角度看，推荐列表是在逐渐变化的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;33-其他&quot;&gt;3.3 其他&lt;/h3&gt;

&lt;p&gt;其他一些论文中提到了，但是没有放到图中的，大概有这些：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用户看过多少同频道的视频？&lt;/li&gt;
  &lt;li&gt;用户上一次看同频道或同主题的视频是什么时候？&lt;/li&gt;
  &lt;li&gt;用户过往与相似视频的交互特征特别重要&lt;/li&gt;
  &lt;li&gt;来自召回模块的特征&lt;/li&gt;
  &lt;li&gt;用户是否登录&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-模型训练与线上服务-1&quot;&gt;4. 模型训练与线上服务&lt;/h2&gt;

&lt;p&gt;直觉来看，既然将排序问题转化为预测问题，似乎应该和常见的回归模型一样，用均方差等作为损失函数才对，而YouTube并没有这样做，而是用 Cross-Entropy 结合 Logistic Regression，为什么可以这么做呢？&lt;/p&gt;

&lt;p&gt;我们知道，Sigmoid函数可以通过对对数几率进行线性回归推导得到：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;odds=\frac{\hat{y}}{1-\hat{y}} \\
log(odds)=log(\frac{\hat{y}}{1-\hat{y}})=\vec{w}^T\vec{x}+b&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y} = \frac{1}{1+exp(-(\vec{w}^T\vec{x}+b))}&lt;/script&gt;

&lt;p&gt;上面的推导中，出发点是对$odds$的定义，我们将其定义为正样本概率与负样本概率的比例，值越大说明正负样本概率之间差距越大。对第二个式子做简单变换，得到： $odds=exp(\vec{w}^T\vec{x}+b)$。&lt;/p&gt;

&lt;p&gt;前面的$odds$我们可以认为是对点击事件的几率进行计算，也就是$odds(Click)$。下面来考虑基于视频观看时长计算几率。我们假设样本总数为$N$，其中正样本（点击并观看视频）的数量为$K$，正样本中视频观看时长记为$T_i$，负样本的视频观看时长统一认为是1，则$odds(WatchTime)$如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
odds &amp;=\frac{E[T|Clicked]}{E[T|NotClicked]} =\frac{\frac{\sum^{K}_{i}{T_i}}{N-K+\sum^{K}_{i}{T_i}}}{\frac{N-K}{N-K+\sum^{K}_{i}{T_i}}} \\
&amp;=\frac{\sum^{K}_{i}{T_i}}{N-K} \\
&amp;=\frac{\sum^{K}_{i}{T_i}}{N}*\frac{N}{N-K} \\
&amp;=\frac{\sum^{K}_{i}{T_i}}{N}*\frac{1}{1-K/N} \\
&amp;=\frac{E[T]}{1-ctr}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;于是，当$ctr$较小时，$odds$是接近于$E[T]$的；而YouTube框架图中的这看似诡异的部分，背后思想则源于此：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4034/assets/youtube-dnn-ranking-serving.jpg&quot; alt=&quot;Ranking Serving&quot; /&gt;&lt;/p&gt;

&lt;p&gt;serving时采用几率$odds$，而不是$sigmoid$来作为对视频观看时长的近似。&lt;/p&gt;

&lt;p&gt;而训练时，采用 Weighted Logistic Regression：对正样本按$T_i$加权，对负样本按$1$加权。&lt;/p&gt;

&lt;h1 id=&quot;结语&quot;&gt;结语&lt;/h1&gt;

&lt;p&gt;把这篇论文读下来，零零散散花了我三四天；整理成脑图的过程中，陆续发现了很多细节问题，又花了一天；写博客的过程中，抠细节、查资料、补知识点，花了三天时间。这一番折腾下来实在太累，好在YouTube的这篇论文也完全值得我这番精读。&lt;/p&gt;

&lt;p&gt;目前文中还是不得已的留下了很多未找到答案的疑问，留着后续慢慢填坑了。&lt;/p&gt;

&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/2959100.2959190&quot;&gt;论文地址&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52169807&quot;&gt;王喆-整体介绍&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52504407&quot;&gt;王喆-十个工程问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61827629&quot;&gt;王喆-模型Serving&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38638747&quot;&gt;工程再现&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">概述</summary></entry><entry><title type="html">自动文本摘要</title><link href="http://localhost:4034/text-summarization/2019/03/15/automatic-text-summarization.html" rel="alternate" type="text/html" title="自动文本摘要" /><published>2019-03-15T17:00:00+08:00</published><updated>2019-03-15T17:00:00+08:00</updated><id>http://localhost:4034/text-summarization/2019/03/15/automatic-text-summarization</id><content type="html" xml:base="http://localhost:4034/text-summarization/2019/03/15/automatic-text-summarization.html">&lt;p&gt;最近因为项目需要，加上个人兴趣，就找了几篇有关自动文本摘要的综述论文，简单做了些调研、学习，这里做个小结。&lt;/p&gt;

&lt;h1 id=&quot;0概述&quot;&gt;0、概述&lt;/h1&gt;

&lt;p&gt;自动文本摘要，顾名思义，就是自动的从文本中生成摘要。&lt;/p&gt;

&lt;p&gt;其实这方面的研究最早在1950年代就开始了，但一直得不到大众的关注，在国际上尚且如此，在国内的情况就更加尴尬了。基于中文文本的自动摘要，在国内能找到的资料、工具并不多。&lt;/p&gt;

&lt;h1 id=&quot;1应用场景&quot;&gt;1、应用场景&lt;/h1&gt;

&lt;p&gt;自动文本摘要能用在哪些地方呢？从个人习惯来说，我倾向于把日常接触到的文字内容分为“水货”和“干货”两种。&lt;/p&gt;

&lt;p&gt;“水货”是指哪些呢？就是那些看完之后没有太多实际收获的内容，比如很多公众号里的鸡汤文、鸡血文、狗血文等等，对于很多人而言，小说类侧重故事性的文章，也都是“水货”。总的来说，我们发现，其实自动文本摘要并不适用于这一类内容，因为读者接触这些内容是为了来体验、来感受的，而不是抱着功利心来的。&lt;/p&gt;

&lt;p&gt;自动文本摘要主要还是应用于“干货”上，新闻文章、科学文献、股市研报等等，人们从这些内容中，想要的是新的信息收获。&lt;/p&gt;

&lt;p&gt;那沿着这个思路，我们就可以想到自动摘要的应用场景都有哪些了。&lt;/p&gt;

&lt;p&gt;用在新闻文章上，我们可以看到新闻快报、头条，像我几乎每天上班路上都会打开的虎嗅早报、36氪早报，以及微博上的新闻推送，其实是能通过自动摘要来生成的。&lt;/p&gt;

&lt;p&gt;用在科学文献上，我们更快速的看论文，涨知识。&lt;/p&gt;

&lt;p&gt;用在股市研报上，我们看一眼就能知道A股又要跌多少。&lt;/p&gt;

&lt;p&gt;这是第一层次的思维，我们不妨进一步的想象：如果同时用在多篇新闻上，或者多篇论文上，或者多篇研报上，我们能看到些什么？&lt;/p&gt;

&lt;p&gt;用在特定事件的多篇新闻报道上，我们能更完整的看到事件的全貌。&lt;/p&gt;

&lt;p&gt;用在特定领域的论文上，我们能看到这个领域的分支、进展。&lt;/p&gt;

&lt;p&gt;用在股市研报上，我们能看到市场对特定股票的态度。&lt;/p&gt;

&lt;h1 id=&quot;2任务拆解&quot;&gt;2、任务拆解&lt;/h1&gt;

&lt;p&gt;从数据源来看，我们发现自动文本摘要可以分为两大块方向：单文档摘要和多文档摘要。&lt;/p&gt;

&lt;p&gt;可能有些同学会想，多文档的情况下，直接拼在一起然后用单文档摘要的技术去处理不就可以了吗？确实这是一种思路，但这种思路存在的问题是，虽然有着相似的主题，但不同文档的侧重点不同，而如果直接当做一篇文档来处理，可能会去掉一些相对小众的主题信息。&lt;/p&gt;

&lt;p&gt;从结果来看，自动摘要还能分为两大块方向：抽取式(extraction)和生成式(abstraction)。&lt;/p&gt;

&lt;p&gt;抽取式指的是从原始文本中抽取关键的词句，来组成一篇摘要；而生成式则是从原始文本中通过一些较为高级、复杂的技术，生成出一篇摘要来，会出现一些原文中完全没出现过的词句。&lt;/p&gt;

&lt;p&gt;简单思考后，我们可以发现，抽取式可能更适用于长文本，因为长文本中主题信息分布得比较散，也能有比较多的句子可以用来抽取。然而当面对短文本时，比如两三百词的文本，要做成一两句话的摘要，抽取式可能就很难有较好的效果了，因为这两三百词可能是由八九个句子组成的，而这八九个句子每个都有不同的重要信息，简单从中抽取一两个句子，肯定会有信息遗漏。&lt;/p&gt;

&lt;p&gt;不难想到，单文档摘要比多文档摘要简单一些，抽取式比生成式要简单一些。也正因如此，很多人在写文本摘要的算法博客以及工业实用时，都只讲TextRank，因为这是最好实现的抽取式文本摘要，而且后面我们会提到，这个算法连训练集都不需要！&lt;/p&gt;

&lt;h1 id=&quot;3效果评估&quot;&gt;3、效果评估&lt;/h1&gt;

&lt;p&gt;在展开来谈算法之前，有必要先提一下自动摘要的效果评估方式。一方面是没有效果评估就没法谈优化、没法谈项目贡献，在公司中，这样的项目可能根本就无法通过立项；另一方面也是怕同学们在看了后面一大堆算法之后就不想看这块内容了（笑）。&lt;/p&gt;

&lt;p&gt;最简单粗暴的方式当然就是人工评估啦。这没太多可说的，打分呗。一个分不够就多维度综合打分呗。&lt;/p&gt;

&lt;p&gt;但人力成本那么高，自然还是得想办法出一些指标来自动评估了。&lt;/p&gt;

&lt;p&gt;在对自动摘要进行评估时，我们主要是在想两个问题：&lt;/p&gt;

&lt;p&gt;1、对于文档D来说，摘要A是不是足够好？&lt;/p&gt;

&lt;p&gt;足够好意味着：摘要应该包含原文尽可能多的信息，且尽可能短，而且读起来通顺。&lt;/p&gt;

&lt;p&gt;于是我们可以针对信息量给出一个打分，针对长度给出一个打分，针对可读性给出一个打分。假如三个打分都达到了我们所要的水平，就能认为特定摘要足够好。&lt;/p&gt;

&lt;p&gt;2、同样基于文档D，摘要A是不是比摘要B好？&lt;/p&gt;

&lt;p&gt;我们拿到了信息量、长度、可读性三个打分，然后在判断对两篇摘要孰优孰劣的时候，需要将这些打分通过某种方式整合成一个打分，才能做比较。&lt;/p&gt;

&lt;p&gt;这就意味着，我们需要在信息量、长度、可读性之间做一些权衡，也就是计算机学科里常说的 tradeoff 。&lt;/p&gt;

&lt;p&gt;如何基于信息量打分、如何基于长度打分、如何基于可读性打分、如何权衡三个打分，对于这些问题给出不同解决方案，就是不同评估方式之间的本质区别。&lt;/p&gt;

&lt;h2 id=&quot;rouge&quot;&gt;ROUGE&lt;/h2&gt;

&lt;p&gt;目前比较常用的是ROUGE类的指标，ROUGE=Recall-Oriented Understudy for Gisting Evaluation，字面意思是：用于要点评估的召回导向的替代（原谅我翻译渣…）。&lt;/p&gt;

&lt;p&gt;我们假设有一组参考摘要 $R={r_1,r_2,…,r_m}$ ； $s$ 作为自动生成的摘要； $\Phi_n(d)$ 表示特定文档的n-gram 0-1向量，长度为所有可能的n-gram数量。&lt;/p&gt;

&lt;p&gt;于是我们常见的&lt;strong&gt;ROUGE-N&lt;/strong&gt;是这样定义的：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ROUGE_n(s)=\frac{\sum_{r\in R}(\Phi_n(r)*\Phi_n(s))}{\sum_{r\in R}(\Phi_n(r)*\Phi_n(r))}&lt;/script&gt;

&lt;p&gt;简单来说，就是(重叠的N-gram数)/(参考摘要中的N-gram数)。好了，熟悉机器学习的同学们请坐下，这确实就是Recall。&lt;/p&gt;

&lt;p&gt;ROUGE-N是基于N-grams来计算的，后来有人想出来用最长共同子串（LCS），同时改Recall为F-measure，这就是&lt;strong&gt;ROUGE-L&lt;/strong&gt;：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ROUGE_L(s)=\frac{(1+\beta^2)R_{LCS}P_{LCS}}{R_{LCS}+\beta^2P_{LCS}}&lt;/script&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{LCS}(s)=\frac{\sum LCS(r_i, s)}{\sum |r_i|}; P_{LCS}(s)=\frac{\sum LCS(r_i,s)}{|s|}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;ROUGE-W&lt;/strong&gt;: 从ROUGE-L改进而来，加了权重。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ROUGE-S&lt;/strong&gt;: Skip-bigram based co-occurrence statistics. Skip-bigram is any pair of words in their sentence order.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ROUGE-SU&lt;/strong&gt;: Skip-bigram plus unigram-based co-occurrence statistics.&lt;/p&gt;

&lt;h2 id=&quot;信息论&quot;&gt;信息论&lt;/h2&gt;

&lt;p&gt;这一类评估方法，主要思想是看两个分布的散度。主要有两种：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;KL divergence&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;KL(p^{\theta_A}||p^{\theta_R})=\sum_{i=1}^{m}p_i^{\theta_A}log \frac{p_i^{\theta_A}}{p_i^{\theta_R}}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Jensen-Shannon divergence&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;JS(p^{\theta_A}||p^{\theta_R})=(KL(p^{\theta_A}||r)+KL(p^{\theta_A}||r))/2=H(r)-H(p^{\theta_A})/2-H(p^{\theta_R})/2&lt;/script&gt;

&lt;h1 id=&quot;4算法&quot;&gt;4、算法&lt;/h1&gt;

&lt;p&gt;接下来就是最核心的部分了——算法。&lt;/p&gt;

&lt;p&gt;正如前面所说的，自动摘要主要分抽取式和生成式两种。基于这两种方式，算法难度上有很大的不同。&lt;/p&gt;

&lt;h2 id=&quot;41-抽取式&quot;&gt;4.1 抽取式&lt;/h2&gt;

&lt;p&gt;抽取式自动摘要的核心思路是，对文档中的所有句子打分，最终挑出若干个权重高的句子来组成摘要。&lt;/p&gt;

&lt;p&gt;最简单粗暴（往往也很靠谱）的做法自然是根据人为规则来挑选句子了，这也是1950年代人们刚开始做自动摘要的思路——利用一些简单的统计特征，例如：句子所包含的单词或短语的数量，句子在文档中的位置，句子是否包含重要单词或短语，句子跟文档标题的词语重叠程度等等，来衡量不同句子的重要性，进而组成摘要。&lt;/p&gt;

&lt;p&gt;当然了，随着发展，算法变得越来越“高级”，效果也越来越好。&lt;/p&gt;

&lt;p&gt;抽取式自动摘要存在两个重要的基础技术：&lt;/p&gt;

&lt;p&gt;1、句子的特征向量表示&lt;/p&gt;

&lt;p&gt;常见的有以下几种：&lt;/p&gt;

&lt;p&gt;基于统计的：我们用一个长度跟语料库（假设$D$由若干个句子组成${s_1,s_2,…,s_M}$）相等的向量 $W=[w_1, w_2, …, w_N]$ 来表示，这个向量中的一个值对应语料库中一个词的重要性。这个值可以是简单的0或1，表示该词语是否存在于特定句子中。又或者是更常见的，TFIDF值：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;TFIDF(s,w)=TF(s,w)*IDF(D,w)=(\frac{count(w \in s)}{len(s)})*log(\frac{len(D)}{len(D|w\in D)+1})&lt;/script&gt;

&lt;p&gt;TF表示词语在该句子中出现的频率；IDF则是通过看该词语是否在很多句子里都存在来评估词语是否“过于常见”。&lt;/p&gt;

&lt;p&gt;基于潜在语义的：这种出来的特征向量长度不一，基本是可以人为控制的，旨在找到隐藏在词句背后的潜在语义特征，比如LDA，word2vec等等，一般缺少明确的可解释性。&lt;/p&gt;

&lt;p&gt;LDA是在构建了TFIDF矩阵后，运用SVD将其拆分成是三个子矩阵，并将其中两个子矩阵提出来相乘得到句子-主题的一个向量。&lt;/p&gt;

&lt;p&gt;word2vec则是通过神经网络进行学习而得。&lt;/p&gt;

&lt;p&gt;当然了，你也可以把上面几种特征向量都拼在一起来用。&lt;/p&gt;

&lt;p&gt;2、句子间的相似度计算&lt;/p&gt;

&lt;p&gt;在有了两个句子的特征向量后，我们需要基于这两个向量来做相似度计算。&lt;/p&gt;

&lt;p&gt;最常用的自然是余弦相似度了：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;CosSim(s_1,s_2)=\frac{s_1*s_2}{|s_1|*|s_2|}&lt;/script&gt;

&lt;p&gt;也就是计算这两个向量间角度的余弦值。&lt;/p&gt;

&lt;p&gt;偶尔可能还会用到Jaccard系数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(v_i,v_j)=\frac{\sum_k min(v_{ik}, v_{jk})}{\sum_kmax(v_{ik},v_{jk})}&lt;/script&gt;

&lt;p&gt;再其他的就很少见了。&lt;/p&gt;

&lt;h3 id=&quot;411-图&quot;&gt;4.1.1 图&lt;/h3&gt;

&lt;p&gt;大名鼎鼎的TextRank和LexRank就是这一类算法。主要都是参考了PageRank的思想。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TextRank&lt;/strong&gt;的好处太多：易于实现、不需要训练集、效果还不错，总而言之，特别适合伸手党。&lt;/p&gt;

&lt;p&gt;就PageRank具体而言，我们先构造一个图 $G={V,E}​$ 。把网页作为一个点，而如果 $V_j​$ 后跟随着 $V_i ​$ ，我们则认为存在一条 $V_j =&amp;gt; V_i​$ 的边。先对图中所有的点赋初始值，然后按照以下公式持续迭代：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;WS(V_i)=(1-d)+d*\sum_{V_j\in IN(V_i)} \frac{w_{ji}}{\sum_{V_k \in OUT(V_j)} w_{jk}}*WS(V_j)&lt;/script&gt;

&lt;p&gt;$d$ 称为阻尼系数，一般取0.85。从迭代的公式中，可以看到，对于特定一个点，分值取决于指向它的其它点的分值，该公式既考虑了这个点有多少入边，还考虑了指向它的点本身有多少出边。&lt;/p&gt;

&lt;p&gt;TextRank基本就是把PageRank直接搬了过来：将句子作为点，取所有的点构造全连接图，两个点之间的边的权重则用句子间相似度来计算。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LexRank&lt;/strong&gt;与TextRank基本相似。（好吧，暂时查不到这两者的区别）&lt;/p&gt;

&lt;h3 id=&quot;412-聚类&quot;&gt;4.1.2 聚类&lt;/h3&gt;

&lt;p&gt;这个方向的思路是：在获取了句子的特征向量之后进行聚类，从而把文章能分成几块主题。最后只要从每个主题里面提取一些句子出来，组成摘要就可以了。&lt;/p&gt;

&lt;p&gt;聚类的通用算法自然可以往上套了，比如K-Means，OBSCAN等等。&lt;/p&gt;

&lt;h3 id=&quot;413-分类&quot;&gt;4.1.3 分类&lt;/h3&gt;

&lt;p&gt;另外一种思路是通过训练一个分类模型来判断特定句子是否应该放在摘要中。既然转成了二分类问题，那所有分类模型都能往上面套了。&lt;/p&gt;

&lt;p&gt;比如贝叶斯、决策树、SVM、HMM、CRF、神经网络等等。&lt;/p&gt;

&lt;h3 id=&quot;414-深层次自然语言分析&quot;&gt;4.1.4 深层次自然语言分析&lt;/h3&gt;

&lt;p&gt;除了机器学习，有一些人在尝试着通过一些较复杂的自然语言分析处理技术来进行文本摘要。总的来说，人们尝试对文本进行解构。&lt;/p&gt;

&lt;p&gt;整体的流程是：分割文档、识别词汇链、通过强词汇链来找到重要语句。&lt;/p&gt;

&lt;h3 id=&quot;415-基于群体智能&quot;&gt;4.1.5 基于群体智能&lt;/h3&gt;

&lt;p&gt;太高级了，没看懂……&lt;/p&gt;

&lt;p&gt;particle swarm optimization&lt;/p&gt;

&lt;p&gt;cuckoo optimization&lt;/p&gt;

&lt;p&gt;bacterial foraging optimization&lt;/p&gt;

&lt;h2 id=&quot;42-生成式&quot;&gt;4.2 生成式&lt;/h2&gt;

&lt;p&gt;生成式文本摘要 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/30559757&quot;&gt;https://zhuanlan.zhihu.com/p/30559757&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1、基于RNN&lt;/p&gt;

&lt;p&gt;A Deep Reinforced Model for Abstractive Summarization&lt;/p&gt;

&lt;p&gt;目前最好的基于RNN的Seq2Seq生成式文本摘要模型之一来自Salesforce，在基本的模型架构上，使用了注意力机制（attention mechanism）和强化学习（reinforcement learning）。&lt;/p&gt;

&lt;p&gt;2、基于CNN&lt;/p&gt;

&lt;p&gt;Convolutional Sequence to Sequence Learning&lt;/p&gt;

&lt;p&gt;基于卷积神经网络的自动文本摘要模型中最具代表性的是由Facebook提出的ConvS2S模型，它的编码器和解码器都由CNN实现，同时也加入了注意力机制&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.ilibrary.me/2017/05/15/sumy-textsum%E5%92%8Cfairsqe&quot;&gt;http://blog.ilibrary.me/2017/05/15/sumy-textsum%E5%92%8Cfairsqe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;sumy &lt;a href=&quot;https://github.com/miso-belica/sumy&quot;&gt;https://github.com/miso-belica/sumy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;tensorflow-textsum &lt;a href=&quot;https://github.com/tensorflow/models/tree/master/research/textsum&quot;&gt;https://github.com/tensorflow/models/tree/master/research/textsum&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;5中文文本&quot;&gt;5、中文文本&lt;/h1&gt;

&lt;p&gt;关于中文自然语言处理，&lt;a href=&quot;https://github.com/hankcs/HanLP&quot;&gt;HanLP&lt;/a&gt; 是个相当全面的工具，但这是用Java开发的，虽然有提供Python接口（&lt;a href=&quot;https://pypi.org/project/pyhanlp/&quot;&gt;pyhanlp&lt;/a&gt;），但不好改动（太久没用Java，懒得重温…），所以后来我主要还是用 &lt;a href=&quot;https://github.com/letiantian/TextRank4ZH&quot;&gt;TextRank4ZH&lt;/a&gt; ，粗略来看效果也略好一些。&lt;/p&gt;

&lt;h1 id=&quot;6结语&quot;&gt;6、结语&lt;/h1&gt;

&lt;p&gt;通过这段时间的了解，发现这块领域还是很有意思的，但现成的工具比较少，主要也就TextRank了。&lt;/p&gt;

&lt;p&gt;就个人而言，对生成式自动摘要的兴趣更强一些，因为目前项目涉及到的主要是短文本。&lt;/p&gt;

&lt;h1 id=&quot;7引用&quot;&gt;7、引用&lt;/h1&gt;

&lt;p&gt;综述：&lt;/p&gt;

&lt;p&gt;Text Summarization Techniques: A Brief Survey&lt;/p&gt;

&lt;p&gt;A survey on Automatic Text Summarization&lt;/p&gt;

&lt;p&gt;A Survey on Automatic Text Summarization, Dipanjan Das&lt;/p&gt;

&lt;p&gt;A survey on Automatic Text Summarization, N.Nazari&lt;/p&gt;

&lt;p&gt;生成式自动摘要：&lt;/p&gt;

&lt;p&gt;A Deep Reinforced Model for Abstractive Summarization&lt;/p&gt;

&lt;p&gt;Convolutional Sequence to Sequence Learning&lt;/p&gt;</content><author><name></name></author><summary type="html">最近因为项目需要，加上个人兴趣，就找了几篇有关自动文本摘要的综述论文，简单做了些调研、学习，这里做个小结。</summary></entry><entry><title type="html">LeetCode #22</title><link href="http://localhost:4034/leetcode/2018/06/02/leetcode-22.html" rel="alternate" type="text/html" title="LeetCode #22" /><published>2018-06-02T22:30:00+08:00</published><updated>2018-06-02T22:30:00+08:00</updated><id>http://localhost:4034/leetcode/2018/06/02/leetcode-22</id><content type="html" xml:base="http://localhost:4034/leetcode/2018/06/02/leetcode-22.html">&lt;p&gt;最近重新开始了在刷题，也尽量多写一写吧。&lt;/p&gt;

&lt;h1 id=&quot;一题目大意&quot;&gt;一、题目大意&lt;/h1&gt;

&lt;p&gt;指定有N对括号，需要输出所有可能的、形式上正确的括号组合情况。例如N=3时，有&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;[
  “((()))”,
  “(()())”,
  “(())()”,
  “()(())”,
  “()()()”
]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这五种可能的排列。&lt;/p&gt;

&lt;h1 id=&quot;二解题思路&quot;&gt;二、解题思路：&lt;/h1&gt;

&lt;p&gt;主要参考两篇文章：&lt;/p&gt;

&lt;p&gt;https://leetcode.com/problems/generate-parentheses/solution/&lt;/p&gt;

&lt;p&gt;https://blog.csdn.net/runningtortoises/article/details/45625363&lt;/p&gt;

&lt;p&gt;分别有这么几种思路：&lt;/p&gt;

&lt;p&gt;1、暴力破解&lt;/p&gt;

&lt;p&gt;把所有可能的串都输出来，然后逐个判断合法性。&lt;/p&gt;

&lt;p&gt;2、回溯&lt;/p&gt;

&lt;p&gt;3、Closure Number&lt;/p&gt;

&lt;p&gt;这种思路是我最为喜欢的一种。我们可以发现，一个合法的串总是可以递归的表示为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;(&lt;/strong&gt;子串1&lt;strong&gt;)&lt;/strong&gt;子串2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;两个合法的子串以及一对括号。&lt;/p&gt;

&lt;p&gt;想到这一点之后，其实后面的思路很自然的也能想通了：
两个子串的括号对数为N-1，我们只需要遍历所有可能的组合情况就行了，从(0, N-1), (1, N-2), …, (N-1, 0)。
这种思路实际上是按顺序生成 0, 1, …, N 的所有解。&lt;/p&gt;

&lt;p&gt;4、增量&lt;/p&gt;

&lt;p&gt;不断的判断左右括号的数量，进而选择添加左括号还是添加右括号。&lt;/p&gt;

&lt;h1 id=&quot;三具体实现&quot;&gt;三、具体实现：&lt;/h1&gt;

&lt;p&gt;这里就只贴第二种思路的吧。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    递归版
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateParenthesis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generateParenthesis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generateParenthesis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'({}){}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    非递归版
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generateParenthesis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        :type n: int
        :rtype: List[str]
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tmp_res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left_count&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;tmp_res&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'({}){}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;res_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp_res&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;四、其他&lt;/p&gt;

&lt;p&gt;python的好处在于，代码可以相当精简。同样的算法在c里面去实现的话，难度往往会大很多。
python用久了之后，会发现自己“变笨了”，差不多连c都不会用了。
所以偶尔还是得多练练手的。&lt;/p&gt;</content><author><name></name></author><summary type="html">最近重新开始了在刷题，也尽量多写一写吧。</summary></entry><entry><title type="html">聚类算法总结 - Hierarchical Clustering</title><link href="http://localhost:4034/datamining/2015/09/24/hierarchical-clustering.html" rel="alternate" type="text/html" title="聚类算法总结 - Hierarchical Clustering" /><published>2015-09-24T16:22:00+08:00</published><updated>2015-09-24T16:22:00+08:00</updated><id>http://localhost:4034/datamining/2015/09/24/hierarchical-clustering</id><content type="html" xml:base="http://localhost:4034/datamining/2015/09/24/hierarchical-clustering.html">&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;算法&lt;/th&gt;
      &lt;th&gt;概括&lt;/th&gt;
      &lt;th&gt;优缺点&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AGNES&lt;/td&gt;
      &lt;td&gt;典型的凝聚式层次聚类&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DIANA&lt;/td&gt;
      &lt;td&gt;典型的划分式层次聚类&lt;/td&gt;
      &lt;td&gt;划分式层次聚类的复杂度比凝聚式的大得多，所以较为少用。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CURE&lt;/td&gt;
      &lt;td&gt;用到了kd-tree跟heap。&lt;br /&gt;合并两个类的时候，先选若干well-scattered的点。从中挑出离中心最远的点，之后再挑离该点最远的点…如此得到一堆代表点，基于这些点去做层次聚类。&lt;br /&gt;&lt;br /&gt;对于大数据：先随机抽样，再对样本进行分区，然后对每个分区局部聚类，最后对局部聚类进行全局聚类。&lt;/td&gt;
      &lt;td&gt;时间上最坏是：$O(n^2log(n))$&lt;br /&gt;若数据维度较小，可以降到：$O(n^2)$&lt;br /&gt;空间复杂度是：$O(n)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ROCK&lt;/td&gt;
      &lt;td&gt;1.生成相似度矩阵。&lt;br /&gt;2.根据相似度阈值得到邻居矩阵-A。&lt;br /&gt;3.计算链接矩阵-L=A x A &lt;br /&gt;4.计算相似性的度量（Goodness Measure），将相似性最高的两个对象合并。（用到了链接矩阵）&lt;br /&gt;&lt;br /&gt;ROCK算法首先用相似度阀值和共同邻居的概念，从给定的数据相似度矩阵中构建一个稀疏图，然后对该稀疏图使用分层聚类算法进行聚类&lt;/td&gt;
      &lt;td&gt;CURE算法不能处理枚举型数据，而ROCK算法是在CURE基础之上适用于枚举数据的聚结分层聚类算法。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Chameleon&lt;/td&gt;
      &lt;td&gt;1.由数据集构造成一个K-近邻图$G_k$&lt;br /&gt;2.通过图的划分算法将图$G_k$划分成大量的子图，每个子图代表一个初始子簇&lt;br /&gt;3.凝聚式层次聚类&lt;/td&gt;
      &lt;td&gt;Chameleon跟CURE和DBSCAN相比，在发现高质量的任意形状的聚类方面有更强的能力。但是，在最坏的情况下，高维数据的处理代价可能对n个对象需要$O(n^2)$的时间。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;BIRCH&lt;/td&gt;
      &lt;td&gt;用到了$CF&amp;lt;n, LS, SS&amp;gt;$&lt;br /&gt;CF-tree类似于B-树，有两个参数：内部节点平衡因子$B$，叶节点平衡因子$L$，簇半径阈值$T$。&lt;br /&gt;&lt;br /&gt;1.自上而下选择最近的子节点&lt;br /&gt;2.到达子节点后，检查最近的元组$CF_i$能否吸收此数据点&lt;br /&gt;若能吸收，则更新CF值&lt;br /&gt;否则考虑是否可以添加一个新的元组&lt;br /&gt;如果可以，则添加一个新的元组&lt;br /&gt;否则，分裂最远的一对元组，作为种子，按最近距离重新分配其它元组&lt;br /&gt;3.更新每个非叶节点的CF信息，如果分裂节点，在父节点中插入新的元组，检查分裂，直到root&lt;/td&gt;
      &lt;td&gt;BIRCH优点：&lt;br /&gt;1.节省内存。叶子节点放在磁盘分区&lt;br /&gt;2. 在对树进行插入或查找操作很快。&lt;br /&gt;3.一遍扫描数据库即可建树。&lt;br /&gt;4.可识别噪声点。&lt;br /&gt;5. 可作为其他聚类算法的预处理过程&lt;br /&gt;&lt;br /&gt;BIRCH缺点：&lt;br /&gt;1.结果依赖于数据点的插入顺序。&lt;br /&gt;2.对非球状的簇聚类效果不好。&lt;br /&gt;3.对高维数据聚类效果不好。&lt;br /&gt;4.最后得出来的簇可能和自然簇相差很大。&lt;br /&gt;5.在整个过程中算法一旦中断，一切必须从头再来。&lt;br /&gt;6.局部性&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;*BUBBLE&lt;/td&gt;
      &lt;td&gt;把BIRCH算法的中心和半径概念推广到普通的距离空间&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;*BUBBLE-FM&lt;/td&gt;
      &lt;td&gt;通过减少距离的计算次数，提高了BUBBLE算法的效率&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Probabilistic agglomerative clustering&lt;/td&gt;
      &lt;td&gt;距离度量用：&lt;br /&gt;&lt;script type=&quot;math/tex&quot;&gt;dist(C_1,C_2 )=-log ((P(C_1∪C_2))/(P(C_1)P(C_2)) )&lt;/script&gt; &lt;br /&gt;如果dist小于零，则合并两个簇。&lt;/td&gt;
      &lt;td&gt;易于理解&lt;br /&gt;一般跟其他凝聚式层次聚类算法的效率差不多&lt;br /&gt;但是：it outputs only one hierarchy with respect to a chosen probabilistic model; it cannot handle the uncertainty of cluster hierarchies.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name></name></author><summary type="html">算法 概括 优缺点 AGNES 典型的凝聚式层次聚类   DIANA 典型的划分式层次聚类 划分式层次聚类的复杂度比凝聚式的大得多，所以较为少用。 CURE 用到了kd-tree跟heap。合并两个类的时候，先选若干well-scattered的点。从中挑出离中心最远的点，之后再挑离该点最远的点…如此得到一堆代表点，基于这些点去做层次聚类。对于大数据：先随机抽样，再对样本进行分区，然后对每个分区局部聚类，最后对局部聚类进行全局聚类。 时间上最坏是：$O(n^2log(n))$若数据维度较小，可以降到：$O(n^2)$空间复杂度是：$O(n)$ ROCK 1.生成相似度矩阵。2.根据相似度阈值得到邻居矩阵-A。3.计算链接矩阵-L=A x A 4.计算相似性的度量（Goodness Measure），将相似性最高的两个对象合并。（用到了链接矩阵）ROCK算法首先用相似度阀值和共同邻居的概念，从给定的数据相似度矩阵中构建一个稀疏图，然后对该稀疏图使用分层聚类算法进行聚类 CURE算法不能处理枚举型数据，而ROCK算法是在CURE基础之上适用于枚举数据的聚结分层聚类算法。 Chameleon 1.由数据集构造成一个K-近邻图$G_k$2.通过图的划分算法将图$G_k$划分成大量的子图，每个子图代表一个初始子簇3.凝聚式层次聚类 Chameleon跟CURE和DBSCAN相比，在发现高质量的任意形状的聚类方面有更强的能力。但是，在最坏的情况下，高维数据的处理代价可能对n个对象需要$O(n^2)$的时间。 BIRCH 用到了$CF&amp;lt;n, LS, SS&amp;gt;$CF-tree类似于B-树，有两个参数：内部节点平衡因子$B$，叶节点平衡因子$L$，簇半径阈值$T$。1.自上而下选择最近的子节点2.到达子节点后，检查最近的元组$CF_i$能否吸收此数据点若能吸收，则更新CF值否则考虑是否可以添加一个新的元组如果可以，则添加一个新的元组否则，分裂最远的一对元组，作为种子，按最近距离重新分配其它元组3.更新每个非叶节点的CF信息，如果分裂节点，在父节点中插入新的元组，检查分裂，直到root BIRCH优点：1.节省内存。叶子节点放在磁盘分区2. 在对树进行插入或查找操作很快。3.一遍扫描数据库即可建树。4.可识别噪声点。5. 可作为其他聚类算法的预处理过程BIRCH缺点：1.结果依赖于数据点的插入顺序。2.对非球状的簇聚类效果不好。3.对高维数据聚类效果不好。4.最后得出来的簇可能和自然簇相差很大。5.在整个过程中算法一旦中断，一切必须从头再来。6.局部性 *BUBBLE 把BIRCH算法的中心和半径概念推广到普通的距离空间   *BUBBLE-FM 通过减少距离的计算次数，提高了BUBBLE算法的效率   Probabilistic agglomerative clustering 距离度量用： 如果dist小于零，则合并两个簇。 易于理解一般跟其他凝聚式层次聚类算法的效率差不多但是：it outputs only one hierarchy with respect to a chosen probabilistic model; it cannot handle the uncertainty of cluster hierarchies.</summary></entry><entry><title type="html">聚类算法总结 - Partitional Clustering</title><link href="http://localhost:4034/datamining/2015/09/21/partitinoal-clustering.html" rel="alternate" type="text/html" title="聚类算法总结 - Partitional Clustering" /><published>2015-09-21T10:31:05+08:00</published><updated>2015-09-21T10:31:05+08:00</updated><id>http://localhost:4034/datamining/2015/09/21/partitinoal-clustering</id><content type="html" xml:base="http://localhost:4034/datamining/2015/09/21/partitinoal-clustering.html">&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;算法&lt;/th&gt;
      &lt;th&gt;概括&lt;/th&gt;
      &lt;th&gt;优缺点&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;k-means&lt;/td&gt;
      &lt;td&gt;每次从类中求均值作为中心点&lt;br /&gt;用到了EM的思想&lt;br /&gt;目标是最小化sum of squared error&lt;/td&gt;
      &lt;td&gt;要求预设k值&lt;br /&gt;易受噪音和离异点的影响 &lt;br /&gt;对不规则形状的类聚类效果不好&lt;br /&gt;不保证全局最优&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k-means++&lt;/td&gt;
      &lt;td&gt;目标是找到k个合理的初始种子点给k-means。&lt;br /&gt;1. 随机挑个随机点当“种子点”&lt;br /&gt;2. 对于每个点，计算其和最近的“种子点”的距离D(x)并保存，然后把这些距离加起来得到Sum(D(x))。&lt;br /&gt;3. 再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其&amp;lt;=0，此时的点就是下一个“种子点”。&lt;br /&gt;4. 重复2和3直到k个中心被选出来&lt;br /&gt;5. 利用这k个初始的聚类中心来运行标准的k-means算法&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k-modes&lt;/td&gt;
      &lt;td&gt;K-Means算法的扩展&lt;br /&gt;对于分类型数据，用mode求中心点&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k-prototypes&lt;/td&gt;
      &lt;td&gt;结合了k-means和k-modes&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k-medoids&lt;/td&gt;
      &lt;td&gt;每次从类中找一个具体的点来做中心点。目标是最小化absolute error。&lt;br /&gt;PAM是一种典型的k-medoids实现。&lt;/td&gt;
      &lt;td&gt;对噪音和离异点不那么敏感&lt;br /&gt;然而计算量大很多&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CLARA&lt;/td&gt;
      &lt;td&gt;先抽样，再用PAM&lt;/td&gt;
      &lt;td&gt;对于大数据比PAM好点&lt;br /&gt;主要是看sample的效果&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CLARANS&lt;/td&gt;
      &lt;td&gt;每次随机的抓一个medoid跟一般点，然后判断，这两者如果替换的话，能不能减小absolute-error&lt;/td&gt;
      &lt;td&gt;融合了PAM和CLARA两者的优点，是第一个用于空间数据库的聚类算法&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name></name></author><summary type="html">算法 概括 优缺点 k-means 每次从类中求均值作为中心点用到了EM的思想目标是最小化sum of squared error 要求预设k值易受噪音和离异点的影响 对不规则形状的类聚类效果不好不保证全局最优 k-means++ 目标是找到k个合理的初始种子点给k-means。1. 随机挑个随机点当“种子点”2. 对于每个点，计算其和最近的“种子点”的距离D(x)并保存，然后把这些距离加起来得到Sum(D(x))。3. 再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其&amp;lt;=0，此时的点就是下一个“种子点”。4. 重复2和3直到k个中心被选出来5. 利用这k个初始的聚类中心来运行标准的k-means算法   k-modes K-Means算法的扩展对于分类型数据，用mode求中心点   k-prototypes 结合了k-means和k-modes   k-medoids 每次从类中找一个具体的点来做中心点。目标是最小化absolute error。PAM是一种典型的k-medoids实现。 对噪音和离异点不那么敏感然而计算量大很多 CLARA 先抽样，再用PAM 对于大数据比PAM好点主要是看sample的效果 CLARANS 每次随机的抓一个medoid跟一般点，然后判断，这两者如果替换的话，能不能减小absolute-error 融合了PAM和CLARA两者的优点，是第一个用于空间数据库的聚类算法</summary></entry><entry><title type="html">《30天自制操作系统》笔记五六</title><link href="http://localhost:4034/learning-note/2014/04/23/30days-os-part56.html" rel="alternate" type="text/html" title="《30天自制操作系统》笔记五六" /><published>2014-04-23T15:22:11+08:00</published><updated>2014-04-23T15:22:11+08:00</updated><id>http://localhost:4034/learning-note/2014/04/23/30days-os-part56</id><content type="html" xml:base="http://localhost:4034/learning-note/2014/04/23/30days-os-part56.html">&lt;p&gt;书上第五六天所涉及的内容主要是GDT、IDT以及PIC。这两部分我就合在一起写好了。（主要的原因是做完第五天的以后看到代码乱得惨不忍睹，就自己开始整理了一下，随后又发现第六天就是讲分割源文件的，所以就继续看了下去。）&lt;/p&gt;

&lt;p&gt;第五天一上来，作者就介绍了结构体。于是，出现了struct boot_info，struct seg_desc，以及struct gate_desc三者。（命名我是按照自己的习惯来改动的。）&lt;/p&gt;

&lt;p&gt;C语言语法上的东西就不提了。&lt;/p&gt;

&lt;p&gt;有点意思的是，继之前恶心简洁的图形化界面之后，我们这次来做文字显示。&lt;/p&gt;

&lt;p&gt;字体怎么来呢？最简单的一种方法就是按照之前做图像的时候的方法来做，也就是用boxfill8()，但是这样也太不专业了吧= =&lt;/p&gt;

&lt;p&gt;我们有一种好一点的方法，就是重写一个putfont8()函数，用来做字符显示。（ps：后来我改名为print_char()了）直接用作者给的hankaku.txt来导入字体。（其实这个字体包也没有多高端嘛……要用到新的工具makefont.exe。可以从hankaku.txt得到hankaku.bin。之后我们再用bin2obj.exe来将其转化为hankaku.obj文件。同时，对应的修改Makefile。&lt;/p&gt;

&lt;p&gt;值得注意的是：一定要加上”$BIN2OBJ ……“的说明！当时就是因为抄漏而导致了大量的失败。&lt;/p&gt;

&lt;p&gt;而显示变量名按照上面的来做基本也没问题。不过不知道为什么，到后面我多加”#include “bootpack.h”“语句之后，直接就只声明“char s[40]”是不够的，要初始化！可以是”char s[40]={‘0’}”。如果没有初始化，就会发现那个字符就是显示不出来，然后你还以为是print_str或者print_char的问题，对照源代码N次！！！（TAT）&lt;/p&gt;

&lt;p&gt;再来是鼠标的指针，这个其实还是蛮无聊有趣的。为了凸显我跟作者的不一样，我把指针弄成了8x8大小的，结果……其实也还是能用的，而且大小我（我不是处女座……）也刚好合适。&lt;/p&gt;

&lt;p&gt;文件分割不难，略过。也就是多出了graphic.c，dsctbl.c，以及后面的int.c。&lt;/p&gt;

&lt;p&gt;有一点是新学习到的，那就是Makefile的一般规则：&lt;/p&gt;

&lt;h1 id=&quot;general-rules-for-gas-nas-and-obj&quot;&gt;general rules for *.gas, *.nas and *.obj&lt;/h1&gt;
&lt;p&gt;%.gas : %.c Makefile
	$(CC1) -o $&lt;em&gt;.gas $&lt;/em&gt;.c
%.nas : %.gas Makefile
	$(GAS2NASK) $&lt;em&gt;.gas $&lt;/em&gt;.nas
%.obj : %.nas Makefile
	$(NASK) $&lt;em&gt;.nas $&lt;/em&gt;.obj $*.lst
关于Makefile，有个很详细的教程：http://bbs.chinaunix.net/thread-408225-1-1.html
之后得找时间认真学习一下才行。&lt;/p&gt;

&lt;p&gt;本次学习遇到的第一个重难点在于GDT以及IDT。&lt;/p&gt;

&lt;p&gt;其实作者的文笔还是挺好的，写得很顺畅。（虽然到后来发现他有些地方机智的绕掉了……）&lt;/p&gt;

&lt;p&gt;该记住的有：&lt;/p&gt;

&lt;p&gt;GDT大小为2^13*(8B) = 64KB&lt;/p&gt;

&lt;p&gt;/* segment descriptor, 8B &lt;em&gt;/
/&lt;/em&gt; base	       : base_low(2B), base_mid(1B) and base_high(1B)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;limit       : limit_low(1B) and limit_high(1B)&lt;/li&gt;
  &lt;li&gt;access_right: the highest bit is Gbit, when Gbit==1, 
              the unit of limit is PAGE; the highest 4bits are put into the 
      highest 4bits of limit_high. thus, to program, access_right
      is xxxx0000xxxxxxxx; the highest 4bits are “GD00”(used after 
      386), G is Gbit, D means 32-mode or 16-mode.
      lowest 8bits:
      0x00: unused descriptor table
      0x92: for system. RW-.
      0x9a: for system. R-X.
      0xf2: for applications. RW-.
      0xfa: for applications. R-X.
 */
struct seg_desc {
 short 	limit_low;
 short 	base_low;
 char 	base_mid; 
 char 	access_right;
 char 	limit_high; 
 char 	base_high;
};
而后面的gate_desc，类比一下就好。
set_seg_desc，set_gate_desc，init_gdt_idt就慢慢看代码吧。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;C不能直接给GDTR赋值，所以要用load_gdtr，在naskfunc.nas中：&lt;/p&gt;

&lt;p&gt;_load_gdtr:		; void load_gdtr(int limit, int addr);
	; “MOV [ESP+6] [ESP+4]”
	MOV	AX, [ESP+4]	; limit
	MOV	[ESP+6], AX
	LGDT	[ESP+6]
	RET
看起来，这段函数似乎做的就是”MOV [ESP+6] [ESP+4]”但是为什么要这么做呢？为什么不直接”LGDT [ESP+4]”呢？
这其中可是大有奥秘的。&lt;/p&gt;

&lt;p&gt;首先，GDTR的低16位是段上限，高32位是地址。我们不能直接用MOV来赋值，而只能直接指定一个内存地址，让它去读这48位。想想看，假设我们传的段上限是0x0000ffff，而地址是00270000（事实上我们用的也就是这个）。这时候，地址从ESP+4往高处走是：【FF FF 00 00 00 00 27 00】。但我们希望给GDTR的是这样一部分：【FF FF 00 00 27 00】那可以看到，作者在这里把ESP+4赋值到ESP+6，然后就变成了【FF FF FF FF 00 00 27 00】，只要直接从ESP+6开始读就可以了。&lt;/p&gt;

&lt;p&gt;哎，在这里实在不得不感叹一声作者太神了！事实上如果你传参数的时候，两个参数的位置如果换一下的话，你会发现很不好处理！（我一开始是想这么干来着。）&lt;/p&gt;

&lt;p&gt;set_seg_desc太高深，跳过。（作者也没讲多少）&lt;/p&gt;

&lt;p&gt;然后就到PIC。一到硬件就各种蛋疼哎！&lt;/p&gt;

&lt;p&gt;PIC指的是Programmable interrupt controller。&lt;/p&gt;

&lt;p&gt;然后看图：&lt;/p&gt;

&lt;p&gt;用图比较容易理解。&lt;/p&gt;

&lt;p&gt;简而言之，PIC监视着输入管脚的8个中断信号，只要有一个中断信号进来，就将唯一的输出管脚信号变成ON，并通知CPU。&lt;/p&gt;

&lt;p&gt;然后下面是一段咋看之下很不明觉厉的代码：&lt;/p&gt;

&lt;p&gt;void init_pic(void);&lt;/p&gt;

&lt;p&gt;#define PIC0_ICW1	0x0020
#define PIC0_OCW2	0x0020
#define PIC0_IMR	0x0021
#define PIC0_ICW2	0x0021
#define PIC0_ICW3	0x0021
#define PIC0_ICW4	0x0021
#define PIC1_ICW1	0x00a0
#define PIC1_OCW2	0x00a0
#define PIC1_IMR	0x00a1
#define PIC1_ICW2	0x00a1
#define PIC1_ICW3	0x00a1
#define PIC1_ICW4	0x00a1 
/* Initialization of pic &lt;em&gt;/
void init_pic (void) {
	io_out8(PIC0_IMR,  0xff  ); /&lt;/em&gt; disable all interrupts &lt;em&gt;/
	io_out8(PIC1_IMR,  0xff  ); /&lt;/em&gt; disable all interrupts */&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;io_out8(PIC0_ICW1, 0x11  ); /* edge trigger mode*/
io_out8(PIC0_ICW2, 0x20  ); /* IRQ-7 is received by INT20-27 */
io_out8(PIC0_ICW3, 1 &amp;lt;&amp;lt; 2); /* PIC1 is connected by IRQ2*/
io_out8(PIC0_ICW4, 0x01  ); /* no-buffer mode */

io_out8(PIC1_ICW1, 0x11  ); /* edge trigger mode */
io_out8(PIC1_ICW2, 0x28  ); /* IRQ-15 is received by INT28-2f */
io_out8(PIC1_ICW3, 2     ); /* PIC1 is connected by IRQ2 */
io_out8(PIC1_ICW4, 0x01  ); /* no-buffer mode */

io_out8(PIC0_IMR,  0xfb  ); /* 11111011 disable all except PIC1 */
io_out8(PIC1_IMR,  0xff  ); /* 11111111 disable all interrupt */ } 简单的翻译一下，IMR指的是interrupt mask register，ICW指的是&quot;initial control word&quot;，都是8位寄存器。 IMR中8位分别对应8个IRQ信号，如果某一位为1，则该为对应的信号被屏蔽，PIC就忽略之。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ICW不一定是16位，因硬件而不同。有4个，分别编号1~4，共有4个字节的数据。&lt;/p&gt;

&lt;p&gt;ICW1和4与硬件有关，忽略之。&lt;/p&gt;

&lt;p&gt;ICW3是有关主从连接的设定，对主PIC而言，第几号IRQ与从PIC相连，是用8位来决定的。如果把这些为全部设为1，则主PIC能驱动8个从PIC。&lt;/p&gt;

&lt;p&gt;不过呢……这个是硬件决定的，我们也无力。&lt;/p&gt;

&lt;p&gt;所以只能改ICW2咯。&lt;/p&gt;

&lt;p&gt;ICW2决定了IRQ以哪一号中断通知CPU。通过PIC用数据信号线传送给CPU“0xcd 0x??”来实现的。这里的0xcd实际上就是调用BIOS时用的INT指令。&lt;/p&gt;

&lt;p&gt;这次以INT0x20~0x2f接收中断信号IRQ0~15而设定的。&lt;/p&gt;

&lt;p&gt;开始看程序，注意鼠标时IRQ12, 键盘是IRQ1。&lt;/p&gt;

&lt;p&gt;void inthandler21(int &lt;em&gt;esp)
/&lt;/em&gt; interrupt from PS/2 keyboard */
{
	struct boot_info *binfo = (struct boot_info *) BOOT_ADDR;
	boxfill8(binfo-&amp;gt;vram, binfo-&amp;gt;scrnx, BLACK, 0, 0, 32 * 8 - 1, 15);
	print_str(binfo-&amp;gt;vram, binfo-&amp;gt;scrnx, 0, 0, WHITE, “INT 21 (IRQ-1) : PS/2 keyboard”);
	for (;;) {
		io_hlt();
	}
}
完了之后还得让它执行IRETD：
_asm_inthandler21:
		PUSH	ES
		PUSH	DS
		PUSHAD
		MOV		EAX,ESP
		PUSH	EAX
		MOV		AX,SS
		MOV		DS,AX
		MOV		ES,AX
		CALL	_inthandler21
		POP		EAX
		POPAD
		POP		DS
		POP		ES
		IRETD
关于栈，不解释。&lt;/p&gt;

&lt;p&gt;这些差不多就是今天全部的内容了。（唉，累……）&lt;/p&gt;</content><author><name></name></author><summary type="html">书上第五六天所涉及的内容主要是GDT、IDT以及PIC。这两部分我就合在一起写好了。（主要的原因是做完第五天的以后看到代码乱得惨不忍睹，就自己开始整理了一下，随后又发现第六天就是讲分割源文件的，所以就继续看了下去。）</summary></entry><entry><title type="html">《30天自制操作系统》笔记四</title><link href="http://localhost:4034/learning-note/2014/04/22/30days-os-part4.html" rel="alternate" type="text/html" title="《30天自制操作系统》笔记四" /><published>2014-04-22T11:22:17+08:00</published><updated>2014-04-22T11:22:17+08:00</updated><id>http://localhost:4034/learning-note/2014/04/22/30days-os-part4</id><content type="html" xml:base="http://localhost:4034/learning-note/2014/04/22/30days-os-part4.html">&lt;p&gt;第四天我们所要做的事情是使用指针以及显示一个简单的图形界面。&lt;/p&gt;

&lt;p&gt;对于有C语言基础的人来说，指针这一部分基本没问题，主要还是图形界面的设置上。&lt;/p&gt;

&lt;p&gt;我们要修改的是bootpack.c以及naskfunc.nas。在naskfunc.nas中加入了一些IO相关的函数：&lt;/p&gt;

&lt;p&gt;; io interrupt
GLOBAL		_io_hlt, _io_cli, _io_sti, _io_stihlt
; io in
GLOBAL		_io_in8, _io_in16, _io_in32
; io out
GLOBAL 	_io_out8, _io_out16, _io_out32
; about EFLAGS
GLOBAL		_io_load_eflags, _io_store_eflags
值得一提的是最后的两个函数。EFLAGS是一个存储着各种标志的寄存器。&lt;/p&gt;

&lt;p&gt;接下来就是C语言的天地了。&lt;/p&gt;

&lt;p&gt;关于颜色，由于这次使用的是320x200的8位颜色模式，也就是最多只能使用0~255共256种颜色了。这里我们只用16种：&lt;/p&gt;

&lt;p&gt;先来初始化调色板：init_palette()&lt;/p&gt;

&lt;p&gt;void init_palette (void) {
	static unsigned char table_rgb[16 * 3] = {
		/&lt;em&gt;R, G, B&lt;/em&gt;/
		0x00, 0x00, 0x00,	/*  0:black&lt;em&gt;/
		0xff, 0x00, 0x00,	/&lt;/em&gt;  1:light red&lt;em&gt;/
		0x00, 0xff, 0x00,	/&lt;/em&gt;  2:light green&lt;em&gt;/
		0xff, 0xff, 0x00,	/&lt;/em&gt;  3:light yellow&lt;em&gt;/
		0x00, 0x00, 0xff,	/&lt;/em&gt;  4:light blue&lt;em&gt;/
		0xff, 0x00, 0xff,	/&lt;/em&gt;  5:light purple&lt;em&gt;/
		0x00, 0xff, 0xff,	/&lt;/em&gt;  6:soft light blue&lt;em&gt;/
		0xff, 0xff, 0xff,	/&lt;/em&gt;  7:white&lt;em&gt;/
		0xc6, 0xc6, 0xc6,	/&lt;/em&gt;  8:light grey&lt;em&gt;/
		0x84, 0x00, 0x00,	/&lt;/em&gt;  9:dark red&lt;em&gt;/
		0x00, 0x84, 0x00,	/&lt;/em&gt; 10:dark green&lt;em&gt;/
		0x84, 0x84, 0x00,	/&lt;/em&gt; 11:dark yellow&lt;em&gt;/
		0x00, 0x00, 0x84,	/&lt;/em&gt; 12:dark blue&lt;em&gt;/
		0x84, 0x00, 0x84,	/&lt;/em&gt; 13:dark purple&lt;em&gt;/
		0x00, 0x84, 0x84,	/&lt;/em&gt; 14:soft dark blue&lt;em&gt;/
		0x84, 0x84, 0x84	/&lt;/em&gt; 15:dark grey*/
	};
	set_palette (0, 15, table_rgb);
	return ;
}
其实主要就是对“调色板”table_rgb进行声明（虽然看起来真的很恶心……），然后再用set_palette来设置：
void set_palette (int start, int end, unsigned char *rgb) {
	int i;
	int eflags = io_load_eflags();
	io_cli();&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;io_out8(0x03c8, start);	
for (i = start; i &amp;lt;= end; ++i) {
	io_out8(0x03c9, *(rgb+0) / 4);
	io_out8(0x03c9, *(rgb+1) / 4);
	io_out8(0x03c9, *(rgb+2) / 4);
	rgb += 3;
}
io_store_eflags(eflags);
return ; } 这里跟作者给的代码有一点点的不同就在于我把rgb[0]改成了*(rgb+0)，主要是觉得在之前声明 的时候rgb是数组，如果第一眼看循环体内的代码可能会觉得是只用到了rgb数组的前三个。事实上，因为后面还有一句“rgb+=3”，使得代码是按照声明的部分当中一行一行的来进行io_out的。 这里我们还用到了和eflags有关的几个函数，是因为要进行防止设置调色板的这个过程被中断了。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而为什么是这样的来io_out，0x03c8以及0x03c9又是哪里来的呢？这里详情可以看：http://community.osdev.info/?VGA&lt;/p&gt;

&lt;p&gt;书上的说法是：&lt;/p&gt;

&lt;p&gt;完了以后我们就可以开始用色了。&lt;/p&gt;

&lt;p&gt;这里书上的参考函数：&lt;/p&gt;

&lt;p&gt;void boxfill8(unsigned char *vram, int xsize, unsigned char c, 
		int x0, int y0, int x1, int y1) {
	int x, y;
	for (y = y0; y &amp;lt;= y1; y++)
		for (x = x0; x &amp;lt;= x1; x++)
			vram[y * xsize + x] = c;
	return;
}
就是绘制矩形。
其中c代表的是color的编号，这里被我重新宏定义了（真不明白作者的宏定义为什么他自己可以看得懂……）&lt;/p&gt;

&lt;p&gt;/* colors */
#define BLACK		0
#define LIGHT_RED	1
#define LIGHT_GREEN	2
#define LIGHT_YELLOW	3
#define LIGHT_BLUE	4
#define LIGHT_PURPLE	5
#define SOFT_LIGHT_BLUE	6
#define WHITE		7
#define LIGHT_GREY	8
#define DARK_RED	9
#define DARK_GREEN	10
#define DARK_YELLOW	11
#define DARK_BLUE	12
#define DARK_PURPLE	13
#define SOFT_DARK_BLUE	14
#define DARK_GREY	15
今天的也就这么多了。&lt;/p&gt;</content><author><name></name></author><summary type="html">第四天我们所要做的事情是使用指针以及显示一个简单的图形界面。</summary></entry><entry><title type="html">《30天自制操作系统》笔记三</title><link href="http://localhost:4034/learning-note/2014/04/21/30days-os-part3.html" rel="alternate" type="text/html" title="《30天自制操作系统》笔记三" /><published>2014-04-21T18:17:54+08:00</published><updated>2014-04-21T18:17:54+08:00</updated><id>http://localhost:4034/learning-note/2014/04/21/30days-os-part3</id><content type="html" xml:base="http://localhost:4034/learning-note/2014/04/21/30days-os-part3.html">&lt;p&gt;第三天的主要内容是要制作一个真正的IPL。然后搭建相关的环境，为后期的C语言使用做准备。&lt;/p&gt;

&lt;p&gt;在第一次做完以后，并没有想得比较仔细的就往后继续了，等到回过头来要写博客时才发现自己忘得差不多了，或者根本就是理解不够，又重新理顺了一遍。&lt;/p&gt;

&lt;p&gt;事实上，从Makefile中可以看到整个框架：&lt;/p&gt;

&lt;p&gt;haribote.img
|-ipl_10.bin
   |- ipl_10.nas
|-haribote.sys
   |- asmhead.bin
      |- asmhead.nas
   |- bootpack.hrb
      |- bootpack.bim
         |- bootpack.obj
           |- bootpack.nas
              |- bootpack.gas
                 |- bootpack.c
         |- naskfunc.obj
           |- naskfunc.nas&lt;/p&gt;

&lt;p&gt;所以可以看到，无论如何我们最终是得到一个haribote.img，以供qemu运行。
然后这里分成了两支：ipl_10.bin和haribote.sys。&lt;/p&gt;

&lt;p&gt;其中，ipl_10.bin是源于ipl_10.nas，是我们的initialprogram loader，它所做的事情是检测磁盘是否有错。&lt;/p&gt;

&lt;p&gt;尔后，haribote.sys则是操作系统的大部分程序了。&lt;/p&gt;

&lt;p&gt;又分为asmhead.bin以及bootpack.hrb，而这两个，从Makefile可以看出，只是简单的拼接在一起就组成了 haribote.sys。正如作者在书中所说的，asmhead.bin是前面一部分要用汇编语言来写的，有关基本设定的。而bootpack.hrb 则源于C语言。&lt;/p&gt;

&lt;p&gt;而bootpack.c要变为机器码，实际上是经过了.c-&amp;gt;.gas-&amp;gt;.nas-&amp;gt;.obj-&amp;gt;.bim-&amp;gt;.hrb这么一个漫长的旅程。其中还引用了一个用汇编语言写成的函数，在naskfunc.nas。&lt;/p&gt;</content><author><name></name></author><summary type="html">第三天的主要内容是要制作一个真正的IPL。然后搭建相关的环境，为后期的C语言使用做准备。</summary></entry><entry><title type="html">《30天自制操作系统》笔记一二</title><link href="http://localhost:4034/learning-note/2014/04/18/30days-os-part12.html" rel="alternate" type="text/html" title="《30天自制操作系统》笔记一二" /><published>2014-04-18T20:48:25+08:00</published><updated>2014-04-18T20:48:25+08:00</updated><id>http://localhost:4034/learning-note/2014/04/18/30days-os-part12</id><content type="html" xml:base="http://localhost:4034/learning-note/2014/04/18/30days-os-part12.html">&lt;p&gt;最近买了本书《30天自制操作系统》，打算跟着这本书来对操作系统有个更为深入的理解。&lt;/p&gt;

&lt;p&gt;这个系列的博客（其实所有博客基本也都是）主要还是作为一个学习的笔记来用的，或者说备忘，所以可能排版也比较随意，大家不要太介意哈~&lt;/p&gt;

&lt;p&gt;第一天主要是安装相关的软件，以及学会用模拟操作系统的运行。我们希望能够在虚拟机中打出QEMU。&lt;/p&gt;

&lt;p&gt;第二天学习到的主要是寄存器的一些知识以及Makefile的基本知识。&lt;/p&gt;

&lt;p&gt;从第一天来看，总的来说，我们所做的事情是：&lt;/p&gt;

&lt;p&gt;helloos.nas ==&amp;gt; 利用nask.exe编译 ==&amp;gt; helloos.img ==&amp;gt; 在qemu中运行。&lt;/p&gt;

&lt;p&gt;这里要用到两个软件：nask.exe以及qemu。&lt;/p&gt;

&lt;p&gt;其实主要还是熟悉整个操作流程而已，更多的还是软件的使用，并没有太多理论上的知识收获。（就我个人来说）&lt;/p&gt;

&lt;p&gt;第二天则比较有意思。&lt;/p&gt;

&lt;p&gt;首先是helloos.nas文件的分析。&lt;/p&gt;

&lt;p&gt;由于这学期也是在学习计算机组成原理，所以汇编学起来也还比较快。&lt;/p&gt;

&lt;p&gt;值得留意的一些指令是：&lt;/p&gt;

&lt;p&gt;ORG    0x7c00 ；指明程序的装载地址&lt;/p&gt;

&lt;p&gt;DB是define byte，1B；&lt;/p&gt;

&lt;p&gt;DW是define word，2B；&lt;/p&gt;

&lt;p&gt;DD是define double-word，4B&lt;/p&gt;

&lt;p&gt;RESB是reserve byte；&lt;/p&gt;

&lt;p&gt;在RESB 0x1fe-$中，$是指前面所已经输出的字节，所以这句指令是说将该文件后面的全部保留下来。&lt;/p&gt;

&lt;p&gt;然后还有寄存器们（16b，分割线后面的是8b）：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AX == accumulator&lt;/td&gt;
      &lt;td&gt;AL, AH&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CX == counter&lt;/td&gt;
      &lt;td&gt;BL, BH&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DX == data&lt;/td&gt;
      &lt;td&gt;CL, CH&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;BX == base&lt;/td&gt;
      &lt;td&gt;DL, DH&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;SP == stack pointer&lt;/p&gt;

&lt;p&gt;BP == base pointer&lt;/p&gt;

&lt;p&gt;SI == source index&lt;/p&gt;

&lt;p&gt;DI == destination index&lt;/p&gt;

&lt;p&gt;ES == extra segment&lt;/p&gt;

&lt;p&gt;CS == code segment&lt;/p&gt;

&lt;p&gt;SS == stack segment&lt;/p&gt;

&lt;p&gt;DS == data segment&lt;/p&gt;

&lt;p&gt;FS, GS：无名&lt;/p&gt;

&lt;p&gt;还有一些需要记一下的是：&lt;/p&gt;

&lt;p&gt;直接输出信息：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MOV	SI, msg		; Source index loop:
MOV	AL, [SI]
ADD	SI, 1
CMP	AL, 0
JE	fin
; call BIOS
MOV	AH, 0x0e
MOV	BX, 15
INT	0x10

JMP	loop msg:
DB	0x0a, 0x0a
DB	&quot;Hello, xavier!&quot;
DB	0x0a
DB	&quot;How are you?&quot;
DB	0x0a
DB	0 主要还是从http://community.osdev.info/?%28AT%29BIOS 可以找到更多信息。（日文！= =||） 0x00007c00~0x00007dff：启动区内容的装载地址
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;helloos.nas ==&amp;gt; helloos.img ==&amp;gt; 在qemu中运行：&lt;/p&gt;

&lt;p&gt;../z_tools/nask.exe helloos.nas&lt;/p&gt;

&lt;p&gt;../z_tools/make.exe -r helloos.img&lt;/p&gt;

&lt;p&gt;copy helloos.img ..\z_tools\qemu\fdimage0.bin
    ../z_tools/make.exe -C ../z_tools/qemu&lt;/p&gt;

&lt;p&gt;最后就是一些Makefile的入门知识。&lt;/p&gt;

&lt;p&gt;语法就是&lt;/p&gt;

&lt;p&gt;ipl.bin:	ipl.nas Makefile
	../z_tools/nask.exe ipl.nas ipl.bin ipl.lst
要制作ipl.bin就需要文件ipl.nas以及Makefile，需要执行语句：
../z_tools/nask.exe ipl.nas ipl.bin ipl.lst&lt;/p&gt;

&lt;p&gt;Makefile能够分析文件依赖性。
常用的大概是这样：&lt;/p&gt;

&lt;p&gt;default:
	../z_tools/make.exe img&lt;/p&gt;

&lt;p&gt;ipl.bin:	ipl.nas Makefile
	../z_tools/nask.exe ipl.nas ipl.bin ipl.lst&lt;/p&gt;

&lt;p&gt;helloos.img:	ipl.bin Makefile
	../z_tools/edimg.exe	imgin:../z_tools/fdimg0at.tek \
		wbinimg src:ipl.bin len:512 from:0 to:0		imgout:helloos.img&lt;/p&gt;

&lt;p&gt;img:
	../z_tools/make.exe -r helloos.img&lt;/p&gt;

&lt;p&gt;asm:
	../z_tools/make.exe -r ipl.bin&lt;/p&gt;

&lt;p&gt;run:
	../z_tools/make.exe img
	copy helloos.img ..\z_tools\qemu\fdimage0.bin
	../z_tools/make.exe -C ../z_tools/qemu&lt;/p&gt;

&lt;p&gt;install:
	../z_tools/make.exe img
	../z_tools/imgtol.com w a: helloos.img&lt;/p&gt;

&lt;p&gt;clean:
	-del ipl.bin
	-del ipl.lst&lt;/p&gt;

&lt;p&gt;没错，基本上就这么多了~&lt;/p&gt;</content><author><name></name></author><summary type="html">最近买了本书《30天自制操作系统》，打算跟着这本书来对操作系统有个更为深入的理解。</summary></entry></feed>