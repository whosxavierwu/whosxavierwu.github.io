---
layout: post
title:  "汽车类词汇聚类 - 项目总结"
date:   2020-06-21 21:27:00 +0800
categories: clustering
typora-root-url: ../../whosxavierwu.github.io
---

## 概述

这次项目是此前刚进公司的一个练手项目，结果练手了将近一个月……做完项目之后，通过文档整理、部门内分享等形式的总结，除了发现自己技术上不成熟的地方以外，还看到了一些方法论上的问题。

本文决定按照项目的实际历程来复盘、总结，而不是按照项目的常规流程来写。主要是希望通过这样一个写作的过程，让自己也再反思一遍，避免以后重蹈覆辙吧。此外，由于这段时间有每天写日报的要求，正好能看下自己每次写的“明日计划”到底执行得怎样。

## 历程

拿到任务后，我撸起袖子就是干。
### 0427

​		•	0427开发了一版，并在小批量数据中跑通（内容提取、tokenize、特征向量化、词汇聚类）
今日完成
1.     完成了“汽车类词汇聚类”的初步代码开发，在小批量数据中跑通了；具体分为文章内容提取、tokenize、词汇特征向量计算、词汇聚类这四块；
明日计划
1.     细调代码（更细致的数据清洗、用哪些符号分行、词汇特征向量的计算是否有误、尝试其他特征建模方式、KMeans调参等），并在全量数据集中跑通；



### 0428
​		•	0428从全量语料中提取文章，尝试做分句、分词（效率问题，没有全部跑出来），只用了约120万短句；120万短句分词后取top一万的词汇，按任务所说的，尝试构建特征向量；发现卡在了稀疏矩阵的构建上，太慢了。而且如果升到两万，内存不够；
今日完成
一、【汽车类词汇聚类】
1、 从全量车家号数据中提取出文章内容作为全量语料；
2、 尝试对全量语料进行分句、分词。存在代码执行效率问题，未全部跑出，暂时只用跑出来的约120万短句进行后续流程；
3、 基于120万短句，分词后取Top-1w的词汇，基于两词共现次数计算词汇的特征向量（参考新人练手题）；发现构建稀疏特征矩阵（1wx1w）时效率低下，且特征维度如果想升至2w时，内存不够用；
4、 在前一步的结果中尝试基于sklearn跑KMeans聚类，发现同样报了MemoryError，具体原因仍在排查；
明日计划
一、【汽车类词汇聚类】
1、 考虑优化词汇特征向量（词共现矩阵）的构建效率；
2、 考虑如何提升特征维度，需要由1w升至6w；
3、 Debug看为什么KMeans跑出错；



### 0429

​		•	0429由scipy改为MapReduce来构建词汇共现矩阵
今日完成
一、【汽车类词汇聚类】
1、发现用scipy的稀疏矩阵来构建词汇共现矩阵的做法存在效率瓶颈，转为使用MapReduce之后效率大幅度提升。（由数小时降为10分钟内）
2、借此机会，也熟悉了MapReduce开发以及组内的离线开发框架；
明日计划
一、【汽车类词汇聚类】
1、共现矩阵目前是<token_pair, count>的形式，接下来需要考虑能否用MapReduce直接做KMeans聚类，或者转成稀疏矩阵后再调用sklearn进行处理 



### 0430
​		•	0430调整MR的输出格式为token-vec的格式，跑通了。跑出了一个更大的分句语料（三千五百万），得到107w*107w的词汇共现矩阵，取top六万的词汇，分别输出了k=10,50,100,…的KMeans的结果
今日完成
一、【汽车类词汇聚类】
1、将昨天的MapReduce改了一下，改成按<token, count_vector>的形式，并跑通；
2、跑出了一个更大的分句语料（共3555万行，未用全部文章语料），并得到107wx107w的词汇共现矩阵；
3、取Top 6w的词汇，分别输出了利用不同类别数的KMeans算法结果（10，50，100，300，500，700，1000）；
节后计划
一、【汽车类词汇聚类】
1、人工评估不同K值输出的聚类效果，并思考优化方向；（目前程序取Top 10w的词汇，K取1000，2000，3000，4000，5000在执行中）



### 0506
​		•	0506发现bug，之前的MR词汇共现计算是错误的，改了过来。数据量便正常了许多。针对效率做优化。拿到了top6万的词汇特征矩阵，但是sklearn的KMeans特别慢
今日完成
一、【汽车类词汇聚类】
1、今天发现了一个重要的代码bug（编码问题导致之前MapReduce计算词汇共现是错误的），已处理；
2、改了bug之后，数据量变正常了，也大了许多（取Top 6w的话，共现词对有5千万），因此针对执行效率做了些代码优化；目前已经得到Top 6w的词汇特征矩阵；但在基于sklearn的KMeans包做聚类时，发现执行效率特别低；目前安排了K=500的正在跑；
3、尝试开发了一版基于MapReduce计算KMeans，但未调试；
节后计划
一、【汽车类词汇聚类】
1、了解有没有办法优化sklearn的执行效率
2、调通MapReduce版的KMeans；



### 0507
​		•	0507发现还是得改成MiniBatchKMeans，效率上来了。已有N两万、K一千的结果。
今日完成
一、【汽车类词汇聚类】
1、多次尝试优化sklearn的KMeans聚类算法的执行效率，一直没有得到提升；收集资料后决定更换为sklearn的MiniBatchKMeans，效率上来了，但效果（仅从轮廓系数 silhouette score来看）可能略差一些；目前已有N=2w，K=1000的结果，正在跑K=1500和K=2000的结果；
二、【业务学习】
1、参加“码神特训营”课程学习，完成2/13节课的学习；
二、【避坑】
1、使用sklearn的模型进行训练时，经常设置n_jobs=-1，这种做法在python=2.7.3的时候可能会报错，改用python>=2.7.17能避免；
2、对python脚本输出重定向时，需要及时用sys.stdout.flush() 清缓存，否则日志可能要等很久才看的到；
3、多查看博客，参考别人的做法；会更快发现MiniBatchKMeans可能更好用；
4、要及时评估当前算法执行效率、节省时间；而不是丢在一边干等待；
明日计划
一、【汽车类词汇聚类】
1、人为评估聚类效果
2、数据清洗（统一大小写、标点符号过滤）
3、增大数据量（N从2w往上增加）
4、仔细阅读MiniBatchKMeans文档，进行调参（K值、迭代次数等其他参数）；



### 0508
​		•	0508优化了数据清洗。统一大小写、标点符号、并改成pipe的方式并行做tokenize
今日完成
一、【汽车类词汇聚类】
1、主要是花了较多时间在数据清洗上，通过修改PaddleNLP中给出的tokenizer.py，统一成小写、统一标点符号、去除标点符号。并修改成pipe的方式，进而实现多CPU并行inference的效果；
2、通读了sklearn中MiniBatchKMeans的源代码；

明日计划
一、【汽车类词汇聚类】
1、进行聚类效果评估；

### 0509
​		•	0509重跑（基本可以准备分享了）
今日完成
一、【汽车类词汇聚类】
1、主要是利用昨天做了一系列清洗之后的数据，重新出了聚类结果；

下周计划
一、【汽车类词汇聚类】
1、进行聚类效果评估；
2、抽空整理代码、实验数据等，准备分享；

### 0511
​		•	0511整理……
今日完成
一、【汽车类词汇聚类】
1、抽样观察聚类结果；
2、整理代码，拟了一份初步的总结文档；
明日计划
一、【汽车类词汇聚类】
1、整理文档；

### 0512-0517
整理wiki

### 0518
​		•	0518进行case分析
一、【汽车类词汇聚类】
1、wiki有所更新。今天主要是挑了一个具体的输出结果进行了较为细致的分析与评估，初步的结论是：当前的聚类算法方案，聚出来的类中，词汇量2~5的类别效果可接受，词汇量为1以及词汇量>=200的类效果不如预期；
明日计划
一、【汽车类词汇聚类】
1、讨论如何做优化等进一步问题；
### 0519
​		•	0519发现聚类效果随着K值波动特别大，开始怀疑是n_init太小，后来怀疑是init_size太小，再后来怀疑是init=random
今日完成
一、【汽车类词汇聚类】
1、wiki有所更新；
今天上午讨论发现聚类效果随K值的影响波动特别大，开始时怀疑是n_init=1导致，改为n_init=10后问题依旧存在；
仔细研读MiniBatchKMeans库的源代码后，发现原因可能在于init_size=6000太小，改为init_size=20000后问题并未解决；
目前怀疑效果波动是由于初始化时采用随机分配的方式所导致的，已经改init=random为init=k-means++正在跑，明天看效果；
明日计划
一、【汽车类词汇聚类】
1、基于现有结果做数据分析，寻找效果波动大的原因；
### 0520
​		•	0520整理实验数据，分析K值选取；发现CH值和轮廓系数好像有问题
今日完成
一、【汽车类词汇聚类】
1、wiki有所更新；
今天主要是整理了此前做过的多次实验（共计68次），进行了汇总，尝试从中分析K值的选择；
初步看来K值取1000较为合适；
除了 Calinski-Harabasz Index 这个指标，目前正在用Silhouette Score 对之前的结果跑数，看了下其中几个结果，出现了负值，需要进一步分析；
明日计划
一、【汽车类词汇聚类】
1、梳理清楚两个指标的差异，明确为什么Silhouette Score会出现一些负值的现象；
2、挑选Calinski-Harabasz Index较高以及较低的两份结果，人为对比分析，进而判断该指标是否确实适用；

### 0521
​		•	0521梳理不同指标的区别；回查日志发现，MiniBatchKMeans在内部迭代时，inertia波动很大；思考后，尝试进行normalize，发现稳定的多了；
今日完成
一、【汽车类词汇聚类】
1、wiki有所更新
2、梳理清楚inertia、Calinski-Harabasz Index、Silhouette Score的区别；
3、在回查日志时发现，MiniBatchKMeans在每次迭代时内部inertia波动很大，搜集资料、并思考后发现，对数据进行normalize之后（即除去特征向量的模），整体效果更为稳定，可以看到内部迭代时inertia是稳定下降的；且随着K值的增大，整体inertia稳定下降，符合预期；
明日计划
一、【汽车类词汇聚类】
1、对于新的结果，再次看了下Silhouette Score，仍旧都是负值，只是由原来的-0.5、-0.3调整到了-0.07、-0.08的量级，整体有效果提升；但仍需要定位原因、排查问题；

### 0522
​		•	0522整理实验数据，进行分析。观察inertia随着K值的波动情况
今日完成
一、【汽车类词汇聚类】
1、wiki有较大更新；今天重新整理了实验数据，基于正则化前和正则化后做数据对比分析，观察簇内误差平方和（inertia）随K值的波动情况，挑选拐点k=900、k=2000、k=5000进行case分析；
2、分析后整理了至今的一些结论：
聚类算法调优方面：
1、MiniBatchKMeans 的执行效率显著高于 KMeans；虽未进行实验，但从原理、相关资料来看，MiniBatchKMeans 的效果应该只是略差于 KMeans；
2、选择 k-means++ 的初始化方式，一般会优于 random 的初始化方式，但是执行效率会慢很多；
3、提前对特征进行正则化很重要，能让聚类效果更稳定、更良好，同时执行效率也会有所提升；
4、MiniBatchKMeans 在使用时，可以尽量调高 init_size 与n_init，以使聚类效果更稳定；
5、挑选聚类效果指标时应首选 inertia，因为该指标在 KMeans 训练完之后就直接能得到，不需要额外计算，其次再考虑 Calinski-Harabasz 或者 Silhouette 等其他参数，其中 Silhouette Coefficient 计算起来特别慢；
6、挑选K值时，可以绘制 inertia 随着K值的变动情况，再寻找几个关键的拐点，从中挑选较为合适的K值；
聚类效果方面：
1、K值如果取太大，会孤立出许多词汇作为单独的簇，例如K=5000时，会有40%的词汇被孤立，这显然不符合业务预期；
2、聚类出来的小簇（含有词汇量较少，10个以内）通常效果较好，而K值越大，出来的簇普遍就越小一些；相对于k=900而言，k=2000输出的小簇质量相当而数量更多，所以表现更好一些；
3、对于中等大小的簇（如含有10~100个词汇），关键是需要有个更明确一些的业务评估标准，才能进行评判；
4、超大的簇（如含有100个以上词汇）应该尽量少，因为通常而言，这种簇难以在业务中应用；
下周计划
一、【汽车类词汇聚类】
1、整理文档；
### 0525-0526
​		•	0525-0526整理文档
今日完成
一、【汽车类词汇聚类】
1、整理文档wiki
明日计划
一、【汽车类词汇聚类】
整理文档，主要处理问题：
1、inertia随K值的变动曲线中，拐点的物理意义如何解释？
2、为什么Calinski-Harabasz指标随着K值的上升而一直下降？是否合理？

0526
搞定文档

## 0、业务背景

给定百家号中汽车类网页语料，需要从中提取出词汇，并对词汇进行聚类。

## 1、问题定义

最常见的聚类问题是做句子/文档聚类，而这个任务是词汇聚类，处理起来其实也能用相似的方式。聚类问题的整体处理框架还是：

1. 准备好数据；这里指的是准备好语料，包括数据获取、数据清洗、分词等；
2. 对要聚类的item，构建对应的特征向量。在这里item指的是一个词；
3. 选择聚类算法模型进行相应开发；
4. 基于词向量，进行模型训练；
5. 取训练后的标签，进行效果评估；

## 2、数据准备

### 2.1 数据源

源数据是百家号中汽车类网页的结构化数据，有125万条；写一个小脚本提取文章内容主体，得到56万篇文章。由于数据schema不明确，提取规则只是基于部分数据来定的，所以可能存在一些网页数据没能正确解析出文章内容主体。56万篇作为语料基本也够用了。

### 2.2 数据处理

1. 对文章进行分句；
2. 对短句进行分词；
3. 对词进行清洗、处理；

这三步实际上是一起处理的。具体是基于PaddleNLP中分享的[tokenizer](https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/shared_modules/preprocess/tokenizer)做了些修改后使用。tokenizer接收的输入是一个句子，输出是进行tokenize后的词汇序列。实际上tokenizer所调用的模型是对单个字符的词性预测，预测的结果中除了词性（名词、动词等）还会带有“是否新词”的信息，进而达到分词的效果。基于此，我做的改动主要是：

1. 为了对文章进行分句，对每个字符判断是否属于“分句符号”，例如逗号、句号、叹号等；如果是，换行输出，将结果由每行一篇文章的格式变成每行一个分句的形式；（之所以要转换格式，因为后续是通过分句来统计词汇共现程度的）
2. 对于每个字符，在输出前进行了处理：统一大小写、统一标点符号；
3. 标点符号不输出。避免后续被当做一个“词汇”；

## 3、特征工程

机器学习领域的基本共识是，数据和特征决定了整体效果的上限，而模型和算法只是不断地逼近这个上限。简单模型加上巧妙的特征工程之后，是可以得到比高深复杂的模型更好的效果的。

用怎样的特征向量来表示一个词汇，我认为可以分浅层和深层来考虑。深层特征要求对词汇的深层次语义有一定程度的理解，更接近自然语言理解的本质；而浅层特征则只停留在词汇的表面特征，例如词频、词共现等统计指标。

### 3.1 浅层特征

对于词汇的浅层特征，比较简单直接的一种思路是，观察词与词两两之间的共现频率。“共现”可以指两个词出现在同一篇文章、或同一个段落、或同一个句子、或同一个短句；这几种方式的区别在于对词汇上下文考虑的范围不同。

无论哪种方式，我们都需要先统计出词共现矩阵。用$C$表示词共现矩阵，其中元素$c_{ij}$表示词$w_i$与词$w_j$共现的次数。如果预料中共有$N$个词汇，则该矩阵的大小为$N*N$。

通常我们都需要按词频进行一个简单的过滤。在本次语料中，词汇（准确说是token）共有119万个，实际出现过的词对有8100万以上，如果不做删减的基于全量数据处理，后面各部分的效率显然是极低的。在本次任务中，我主要取高频的2~6万词汇。

基于词共现矩阵$C$计算某个词汇$w_i$的特征向量$\vec{v_i}$，可以有这么一些做法：

1. 直接取$C$中对应的一行，即 $\vec{v_i}=(c_{i0}, ..., c_{ij}, ...)$ ，$v_{ij}=c_{ij}$，向量维度为$N$；
2. 在第一种方式的基础上，除去该词汇的总出现次数，即 $v_{ij} = \frac{c_{ij}}{\sum_j^N c_{ij}}$ ；
3. 这第一种方式的基础上，除去与该词汇共现过的词汇的数量，即 $v_{ij} = \frac{c_{ij}}{ count\\{j;c_{ij}>0\\} }$ ；
4. 在第一种方式的基础上，进行MinMax归一化，即 $v_{ij} = \frac{c_{ij} - min(c_{ij}) + \epsilon }{ max(c_{ij};j) - min(c_{ij};j) }$ , $s.t. c_{ij}>0$ ；

### 3.2 深层特征

深层特征要求对词汇有一定的理解，在深度学习领域一般统称为Embedding。当前较为出名的是Word2Vec、ERNIE、BERT。都是通过大型语料预训练好的词向量。

## 4、模型选择

### 4.1 KMeans

KMeans 的核心思想简单明了：

1. 通过某种方式（例如从样本中随机挑选）得到$K$个簇中心的特征向量;
2. 遍历每个样本点（也就是每个词），计算出离它最近的簇中心，分配到该簇中；
3. 对于每个簇，根据其中的所有样本点，重新计算（例如直接取均值）簇中心；
4. 重复2、3两步，直至某个条件；

### 4.2 MiniBatchKMeans

## 5、模型训练

## 6、效果评估

### 6.1 客观指标

| 指标                    | 计算方式 | 值范围 | 值含义 | 优点 | 缺点 |
| ----------------------- | -------- | ------ | ------ | ---- | ---- |
| Inertia                 |          |        |        |      |      |
| Silhouette Coefficient  |          |        |        |      |      |
| Calinski-Harabasz Index |          |        |        |      |      |

### 6.2 主观评估

## 7、实验

## 8、思考

### 8.1 如何确定K值？

一种方案当然就是人为根据经验或者业务需求来拍一个值了。

另外一种相对可量化的做法是手肘法：取不同的K值各跑一边，观察某个指标的变化，通常来说这个指标在K值较小的时候的，会随着K值的增大而以比较快的速度变化，我们通过绘制相应的图像，来找到那个使效果较为稳定的最小的K值。

### 8.2 落地应用场景有哪些？

1. 用于发现数据规律，找到一些潜在的模式；例如我会发现有一类词是“7500公里”、“8000公里”、“4000公里”；
2. 用于发现一些近义词，例如我发现有一个簇里面只有两个词：“档”和“挡”；
3. 可能可以发现同类车；